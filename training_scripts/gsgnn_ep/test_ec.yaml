---
version: 1.0
lm_model:
  bert_models: # bert model(s) definition, one bert model for each node type having text data
    -
      node_type: node
      model_name: "bert-base-uncased"
      gradient_checkpoint: true
gsf:
  basic:
    backend: gloo
    num_gpus: 1
    ip_config: ip_list.txt
    part_config: ./test_ec_1p_4t/test.json
    verbose: false
    debug: false
    save_perf_results_path: null
  gnn:
    model_encoder_type: rgcn
    fanout: "4"
    n_layers: 1
    n_hidden: 128
    mini_batch_infer: true
  input:
    restore_model_path: null
  output:
    save_model_path: null
    save_embed_path: null
  hyperparam:
    dropout: 0.
    lr: 0.001
    lm_tune_lr: 0.0001
    n_epochs: 3
    batch_size: 10
    eval_batch_size: 1024
    bert_infer_bs: 128
    wd_l2norm: 0
    no_validation: false
    evaluation_frequency: 1
  rgcn:
    n_bases: -1
    use_self_loop: true
    use_dot_product: true
    sparse_lr: 1e-2
    use_node_embeddings: false
  edge_classification:
    target_etype:
      - "node,r0,item"
    reverse_edge_types_map: []
    label_field: "label"
    multilabel: false
    num_classes: 11
    num_decoder_basis: 32
    exclude_training_targets: false
