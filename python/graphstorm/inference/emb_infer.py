"""
    Copyright 2023 Contributors

    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
    You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

    Unless required by applicable law or agreed to in writing, software
    distributed under the License is distributed on an "AS IS" BASIS,
    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    See the License for the specific language governing permissions and
    limitations under the License.

    Inferer wrapper for embedding generation.
"""
import logging
from .graphstorm_infer import GSInferrer
from ..model.utils import save_full_node_embeddings as save_gsgnn_embeddings
from ..model import do_full_graph_inference, do_mini_batch_inference
from ..utils import sys_tracker, get_rank, barrier


class GSgnnEmbGenInferer(GSInferrer):
    """ Inferrer for embedding generation tasks.

    ``GSgnnEmbGenInferer`` inherits from the ``GSInferrer`` and use the functions
    provided by ``GSInferrer`` to define the ``infer()`` method that performs one work:

    * Generate node embeddings and save to disk.

    Parameters
    ----------
    model : GSgnnModel
        This model could be one of the built-in GraphStorm prediction models, i.e.,
        ``GSgnnNodeModel``, ``GSgnnEdgeModel``, ``GSgnnLinkPredictionModel``, or model
        classes that inherit them and ``GSgnnNodeModelBase``, ``GSgnnEdgeModelBase``,
        ``GSgnnLinkPredictionModelBase``.
    """
    def infer(self, data, infer_ntypes, save_embed_path, eval_fanout,
            use_mini_batch_infer=False,
            node_id_mapping_file=None,
            save_embed_format="pytorch",
            infer_batch_size=1024):
        """ Do Embedding Generating.

        Parameters
        ----------
        data: GSgnnData
            The GraphStorm dataset
        infer_ntypes : list of str
            List of node types to compute embeddings in the format of
            [ntype1, ntype2, ...].
        save_embed_path : str
            The path where the GNN embeddings will be saved. Must provide.
        eval_fanout: list of int
            Neighbor sampling fanout of each GNN layers used in evaluation and inference.
        use_mini_batch_infer: bool
            Whether to use mini-batch for inference. Default: False.
        node_id_mapping_file: str
            Path to the file storing node id mapping generated by the
            graph partition algorithm. If is None, will not do node ID
            mapping.
            Default: None.
        save_embed_format : str
            Specify the data format of saved embeddings. Currently only support
            PyTorch Tensor.
            Default: "pytorch".
        infer_batch_size: int
            The inference batch size when computing node embeddings with
            mini-batch inference.
        """
        assert save_embed_path is not None, \
            "It requires save embed path for gs_gen_node_embedding"

        sys_tracker.check('start generating embedding')
        self._model.eval()

        if use_mini_batch_infer:
            embs = do_mini_batch_inference(self._model, data, batch_size=infer_batch_size,
                                           fanout=eval_fanout, edge_mask=None,
                                           task_tracker=self.task_tracker,
                                           infer_ntypes=infer_ntypes)
        else:
            embs = do_full_graph_inference(self._model, data, fanout=eval_fanout,
                                           edge_mask=None,
                                           task_tracker=self.task_tracker)
            if infer_ntypes:
                embs = {ntype: embs[ntype] for ntype in infer_ntypes}

        if get_rank() == 0:
            logging.info("save embeddings to %s", save_embed_path)

        g = data.g
        save_gsgnn_embeddings(g,
                              save_embed_path,
                              embs,
                              node_id_mapping_file=node_id_mapping_file,
                              save_embed_format=save_embed_format)
        barrier()
        sys_tracker.check('save embeddings')
