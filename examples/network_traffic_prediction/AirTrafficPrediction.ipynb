{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "782e11df-01f7-44ed-96dc-a3c6e0c34d56",
   "metadata": {},
   "source": [
    "# Air Transportation Network Prediction Using GraphStorm\n",
    "\n",
    "This demonstration notebook provides the end-to-end training and inference pipelines for the air transportation network prediction. For this synthetic air transportation network data, we define the prediction task as a node time series regression, i.e., predicting the total inventory amount.\n",
    "\n",
    "Users may find that the end-to-end pipelines built in this notebook are similar as the [Notebook 1: Use GraphStorm APIs for Building a Node Classification Pipeline](https://graphstorm.readthedocs.io/en/latest/api/notebooks/Notebook_1_NC_Pipeline.html). This notebook, however, has three major differences from the Notebook 1 API example, including:\n",
    "\n",
    "1. A customized RGCN model that can use sliding window method to process time series data for regression;\n",
    "2. A customized node trainer class that can handle the specific evaluation method for time series data;\n",
    "3. A customized node inferrer class that can handle the autoagressive sliding window method during model inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b109b38-24d1-4e45-af3a-0d6f22a2dfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup log level in Jupyter Notebook to show running information\n",
    "import logging\n",
    "logging.basicConfig(level=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acdab68a-8026-4d8b-8aae-de85c27db2fb",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 0. Initialize the GraphStorm Standalone Environment\n",
    "\n",
    "The first step to use GraphStorm is to call `gs.initialize()` for the Standalone mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdd68b1-317d-49b8-8809-596bbd956009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialization\n",
    "NUM_DEMAND_DAYS = 31\n",
    "\n",
    "import graphstorm as gs\n",
    "gs.initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50ed0f4-93e1-4789-bef7-d8bd9b5cbf51",
   "metadata": {},
   "source": [
    "### 1. Setup GraphStorm Dataset and DataLoaders\n",
    "\n",
    "Similar as Pytorch model training pipeline, we create a dataset by constructing `gs.dataset.GSgnnData` class. In most cases, users only need to provide the location of the graph description JSON file, which is created in GraphStorm's gconstruct operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03475a99-d20b-4c76-b9ba-eb3f1d7d7ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a GraphStorm Dataset for the movie_lens graph data generated with GraphStorm test code\n",
    "from graphstorm.dataloading import GSgnnData\n",
    "\n",
    "ml_data = GSgnnData(part_config='./gs_1p/air_traffic.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96a9a8c-6c36-4e53-b5ae-6a20be07c153",
   "metadata": {},
   "source": [
    "Then, we create different `DataLoader`s for training, validation, and testing. As shown below, we allow users to specify different `DataLoader` settings, e.g., `fanout`, `batch_size`, except for a few model-related properties, such as `node_feats`, `edge_feats` and `label_field`.\n",
    "\n",
    "GNN models may only use parts of graph features, therefore, GraphStorm `DataLoader`s allow users to specifies the `node_feats` and `edge_feats` in the format of a dictionary of lists of strings. Keys of the dictionary are node type names, while values are lists of feature name strings.\n",
    "\n",
    "In our synthetic air transportation network, we have both node features and edge features. Below we put them into two dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34593f0d-ead1-4261-b4d7-3ea1be16096c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphstorm.dataloading import GSgnnNodeDataLoader\n",
    "\n",
    "# define dataloaders for training, validation, and testing\n",
    "nfeats_4_modeling = {'airport':['latitude','longitude', 'inventory_amounts']}\n",
    "efeats_4_modeling = {('airport', 'demand', 'airport'): ['demands'], \\\n",
    "                     ('airport', 'traffic', 'airport'): ['capacity', 'traffics']}\n",
    "fanout=[10, 10]\n",
    "train_dataloader = GSgnnNodeDataLoader(\n",
    "    dataset=ml_data,\n",
    "    target_idx=ml_data.get_node_train_set(ntypes=['airport']),\n",
    "    node_feats=nfeats_4_modeling,\n",
    "    edge_feats=efeats_4_modeling,\n",
    "    label_field='inventory_amounts',\n",
    "    fanout=fanout,\n",
    "    batch_size=64,\n",
    "    train_task=True)\n",
    "val_dataloader = GSgnnNodeDataLoader(\n",
    "    dataset=ml_data,\n",
    "    target_idx=ml_data.get_node_val_set(ntypes=['airport']),\n",
    "    node_feats=nfeats_4_modeling,\n",
    "    edge_feats=efeats_4_modeling,\n",
    "    label_field='inventory_amounts',\n",
    "    fanout=fanout,\n",
    "    batch_size=64,\n",
    "    train_task=False)\n",
    "test_dataloader = GSgnnNodeDataLoader(\n",
    "    dataset=ml_data,\n",
    "    target_idx=ml_data.get_node_test_set(ntypes=['airport']),\n",
    "    node_feats=nfeats_4_modeling,\n",
    "    edge_feats=efeats_4_modeling,\n",
    "    label_field='inventory_amounts',\n",
    "    fanout=fanout,\n",
    "    batch_size=64,\n",
    "    train_task=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776cd5af-7c0a-4021-8921-23d70d67b488",
   "metadata": {},
   "source": [
    "### 2. Create a Customized GraphStorm-compatible RGCN Model for the Time Series Node Regression\n",
    "\n",
    "GraphStorm has a set of GNN component modules that could be freely combined for different tasks. This notebook depends on an RGCN model, `RgcnNRModel4TS`, that extends from the `GSgnnModel` and implements the sliding window method in its `forward()` and `predict()` function for node regression by using GaphStorm model APIs. Users can find the details in the `nr_models.py` file.\n",
    "\n",
    "Because our synthetic air transportation network have both static features and time series features, the customized `RgcnNRModel4TS` need to know which features are static or time series. So the `RgcnNRModel4TS` asks this information in its arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba68c6f-d419-4f39-a3c4-340b256a83c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nr_models import RgcnNRModel4TS\n",
    "\n",
    "# initialize the model with specific time series related arugments\n",
    "ts_nfeat_names = {'airport':['inventory_amounts']}\n",
    "ts_efeat_names = {('airport', 'demand', 'airport'): ['demands'], \\\n",
    "                  ('airport', 'traffic', 'airport'): ['traffics']}\n",
    "\n",
    "# import a simplified RGCN model for node classification\n",
    "model = RgcnNRModel4TS(\n",
    "    g=ml_data.g,\n",
    "    num_hid_layers=len(fanout),\n",
    "    node_feat_field=nfeats_4_modeling,\n",
    "    edge_feat_field=efeats_4_modeling,\n",
    "    target_ntype='airport',\n",
    "    ts_nfeat_names=ts_nfeat_names,\n",
    "    ts_efeat_names=ts_efeat_names,\n",
    "    hid_size=128,\n",
    "    ts_size=NUM_DEMAND_DAYS,\n",
    "    window_size=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50883e00-ae86-4773-aa81-935fba9e72b6",
   "metadata": {},
   "source": [
    "### 3. Setup a GraphStorm Evaluator\n",
    "\n",
    "To check the performance during model training, GraphStorm relies on a set of built-in `Evaluator`s for different tasks. Here we create a `GSgnnRegressionEvaluator` for the node time series regression task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d5fca3-f026-460f-97b4-ed63427b1630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup a classification evaluator for the trainer\n",
    "from graphstorm.eval import GSgnnRegressionEvaluator\n",
    "\n",
    "evaluator = GSgnnRegressionEvaluator(eval_frequency=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abb84ae-baff-4d2b-909d-743bb8b9b8b5",
   "metadata": {},
   "source": [
    "### 4. Setup a Trainer and Training\n",
    "\n",
    "For training loop, GraphStorm has different `Trainer`s for specific tasks. GraphStorm's `GSgnnNodePredictionTrainer` is designed to orchestrate dataloaders, models, and evaluators, but cannot handle the sliding window mehtod. So here we extends the `GSgnnNodePredictionTrainer`, replacing its default `node_mini_batch_gnn_predict()` method with a customized method that supports sliding window method for model training and validation, and autoregressive sliding window for inference.  Users can find the details in the `nr_models.py` file.\n",
    "\n",
    "Then we use the customized trainer's `fit()` to train our model. During training, users can check the output log, finding training loss, evaluation metrics, and etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef5ce33e-097a-4256-83b4-928bb8f1a856",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nr_models import NodePredictionTrainer4TS\n",
    "\n",
    "# define a trainer, which is our own customized trainer\n",
    "trainer = NodePredictionTrainer4TS(model)\n",
    "\n",
    "trainer.setup_evaluator(evaluator)\n",
    "trainer.setup_device(gs.utils.get_device())\n",
    "\n",
    "# Train the model with the trainer using fit() function\n",
    "trainer.fit(train_loader=train_dataloader,\n",
    "            val_loader=val_dataloader,\n",
    "            test_loader=test_dataloader,\n",
    "            num_epochs=100,\n",
    "            save_model_frequency=1000,\n",
    "            save_model_path='./models/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46329dac-dbf3-46ce-b900-4c34973772f5",
   "metadata": {},
   "source": [
    "### 5. Visualize Model Performance History\n",
    "\n",
    "Besides the log, we can examine the model performance on the validation, and testing by visualizing evalutors' history properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591e77bd-9528-43fd-9d66-951332c5ca1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# extract evaluation history of metrics from the evaluator's history property\n",
    "val_metrics, test_metrics = [], []\n",
    "for val_metric, test_metric in trainer.evaluator.history:\n",
    "    val_metrics.append(val_metric['rmse'])\n",
    "    test_metrics.append(test_metric['rmse'])\n",
    "\n",
    "# plot the performance curves\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(val_metrics, label='val rmse')\n",
    "ax.plot(test_metrics, label='test rmse')\n",
    "ax.set(xlabel='Iterations', ylabel='Evaluation RMSE')\n",
    "ax.legend(loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd440b9-f332-4111-9e05-6b1523f8776c",
   "metadata": {},
   "source": [
    "### 6. Inference with the Trained Model\n",
    "\n",
    "GraphStorm automatically save the best performed model according to the value specified in the `save_model_path` argument. We can first find out what is the best model and its path. And then restore it by using model's `restore_model()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b0e174-16e7-4473-aed3-b96eb6b3d71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# after training, the best model is saved to disk\n",
    "best_model_path = trainer.get_best_model_path()\n",
    "print('Best model path:', best_model_path)\n",
    "\n",
    "# we can restore the model from the saved path using the model's restore_model() function.\n",
    "model.restore_model(best_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ebe0fb-385a-46e7-a171-e280d9e59a10",
   "metadata": {},
   "source": [
    "To do inference, users can either create a new dataloader as the following code does, or reuse one of the dataloaders defined in training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4e7a2b-5d89-4474-9e7b-6e2a646a0b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup dataloader for inference\n",
    "print(f'========================== Do Inference ================================')\n",
    "infer_dataloader = GSgnnNodeDataLoader(\n",
    "    dataset=ml_data,\n",
    "    target_idx=ml_data.get_node_infer_set(ntypes='airport', mask=None),\n",
    "    node_feats=nfeats_4_modeling,\n",
    "    edge_feats=efeats_4_modeling,\n",
    "    label_field='inventory_amounts',\n",
    "    fanout=fanout,\n",
    "    batch_size=64,\n",
    "    train_task=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f271746-c51e-4138-8543-b69b8fbc34bd",
   "metadata": {},
   "source": [
    "GraphStorm provides a set of `Inferrer`s that can perform highly efficient inference for very large graphs. GraphStorm's `GSgnnNodePredictionInferrer` cannot handle the sliding window mehtod either. Similarly we extends the `GSgnnNodePredictionInferrer`, and specifically implements the autoregressive sliding window method by replacing true time serie values with the predicted ones, and then call the same customized `node_mini_batch_gnn_predict()` method during inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270dc5b7-8cb0-4515-abc1-5c2bbca36836",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nr_models import NodePredictionInferrer4TS\n",
    "\n",
    "# Run inference on the inference dataset\n",
    "infer = NodePredictionInferrer4TS(model)\n",
    "\n",
    "infer.infer(infer_dataloader,\n",
    "            use_mini_batch_infer=True,\n",
    "            save_embed_path=None,\n",
    "            node_id_mapping_file='./gs_1p/node_mapping.pt',\n",
    "            save_prediction_path='./predictions')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f252cfb9-ac19-463d-86e0-ba24347ab123",
   "metadata": {},
   "source": [
    "Now let's check the prediction results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90af92cd-dfcb-4ae7-b29d-fe536e1f6ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The GNN embeddings and predictions on the inference graph are saved to the folder named after the target_ntype\n",
    "!ls -lh ./predictions/airport/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gsf",
   "language": "python",
   "name": "gsf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
