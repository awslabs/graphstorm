<!doctype html>
<html class="no-js" lang="en">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />
<link rel="index" title="Index" href="../genindex.html" /><link rel="search" title="Search" href="../search.html" /><link rel="prev" title="Use Your Own Models" href="own-models.html" />

    <!-- Generated with Sphinx 6.1.3 and Furo 2023.03.27 -->
        <title>Use Text as Node Features - GraphStorm 0.1 documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo.css?digest=fad236701ea90a88636c2a8c73b44ae642ed2a53" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo-extensions.css?digest=30d1aed668e5c3a91c3e3bf6a60b675221979f0e" />
    
    


<style>
  body {
    --color-code-background: #f8f8f8;
  --color-code-foreground: black;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
      }
    }
  }
</style></head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-half" viewBox="0 0 24 24">
    <title>Auto light/dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-shadow">
      <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
      <circle cx="12" cy="12" r="9" />
      <path d="M13 12h5" />
      <path d="M13 15h4" />
      <path d="M13 18h1" />
      <path d="M13 9h4" />
      <path d="M13 6h1" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation">
  <div class="visually-hidden">Hide navigation sidebar</div>
</label>
<label class="overlay toc-overlay" for="__toc">
  <div class="visually-hidden">Hide table of contents sidebar</div>
</label>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <div class="visually-hidden">Toggle site navigation sidebar</div>
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="../index.html"><div class="brand">GraphStorm 0.1 documentation</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle">
          <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
          <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon no-toc" for="__toc">
        <div class="visually-hidden">Toggle table of contents sidebar</div>
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand" href="../index.html">
  
  
  <span class="sidebar-brand-text">GraphStorm 0.1 documentation</span>
  
</a><form class="sidebar-search-container" method="get" action="../search.html" role="search">
  <input class="sidebar-search" placeholder="Search" name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <p class="caption" role="heading"><span class="caption-text">Get Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../install/env-setup.html">Environment Setup</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/quick-start.html">Standalone Mode Quick Start Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/own-data.html">Use Your Own Data Tutorial</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../configuration/index.html">GraphStorm Configurations</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" role="switch" type="checkbox"/><label for="toctree-checkbox-1"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../configuration/configuration-gconstruction.html">Graph Construction</a></li>
<li class="toctree-l2"><a class="reference internal" href="../configuration/configuration-partition.html">Graph Partition</a></li>
<li class="toctree-l2"><a class="reference internal" href="../configuration/configuration-run.html">Training and Inference</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Scale to Giant Graphs</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../scale/distributed.html">Use GraphStorm in a Distributed Cluster</a></li>
<li class="toctree-l1"><a class="reference internal" href="../scale/sagemaker.html">Use GraphStorm on SageMaker</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Advanced Topics</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="own-models.html">Use Your Own Models</a></li>
<li class="toctree-l1 current current-page"><a class="current reference internal" href="#">Use Text as Node Features</a></li>
<li class="toctree-l1"><a class="reference internal" href="#prepare-raw-data">Prepare Raw Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="#construct-graph">Construct Graph</a></li>
<li class="toctree-l1"><a class="reference internal" href="#graphstorm-language-model-configuration">GraphStorm Language Model Configuration</a></li>
<li class="toctree-l1"><a class="reference internal" href="#launch-graphstorm-trainig-without-fine-tuning-bert-models">Launch GraphStorm Trainig without Fine-tuning BERT Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="#launch-graphstorm-trainig-for-both-bert-and-gnn-models">Launch GraphStorm Trainig for both BERT and GNN Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="#only-use-bert-models">Only Use BERT Models</a></li>
</ul>

</div>
</div>

      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          
<div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle">
              <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
              <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon no-toc" for="__toc">
            <div class="visually-hidden">Toggle table of contents sidebar</div>
            <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
          </label>
        </div>
        <article role="main">
          <section id="use-text-as-node-features">
<span id="language-models"></span><h1>Use Text as Node Features<a class="headerlink" href="#use-text-as-node-features" title="Permalink to this heading">#</a></h1>
<p>Many real world graphs have text contents as nodes’ features, e.g., the title and description of a product, and the questions and comments from users. To leverage these text contents, GraphStorm supports language models (LMs), i.e., HuggingFace BERT models, to embed text contents and use these embeddings in Graph models’ training and inference.</p>
<p>There are two modes of using LMs in GraphStorm:</p>
<ul class="simple">
<li><p>Embed text contents with pre-trained LMs, and then use them as the input node features, without fine-tuning the LMs. Training speed in this mode is fast, and memory consumption will be lower. However, in some cases, pre-trained LMs may not fit to the graph data well, and fail to improve performance.</p></li>
<li><p>Co-train both LMs and GML models in the same training loop. This will fine-tune the LMs to fit to graph data. This mode in general can improve performance, but co-train the LMs will consume much more memory, particularly GPU memory, and take much longer time to complete training loops.</p></li>
</ul>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>The current version of GraphStorm requires <strong>ALL</strong> node types must have text features if users want to co-train LM and GNN models.</p>
</div>
<p>To use LMs in GraphStorm, users can follow the same procedure as the <a class="reference internal" href="../tutorials/own-data.html#use-own-data"><span class="std std-ref">Use Your Own Data</span></a> tutorial with some minor changes.</p>
<ul class="simple">
<li><p>Step 1. Prepare raw data to include texts as node data;</p></li>
<li><p>Step 2. Use GraphStorm graph construction tools to tokenize texts and set tokens as node features;</p></li>
<li><p>Step 3. Configure GraphStorm to use LMs to embed tokenized texts as input node features; and</p></li>
<li><p>Step 4. If need, configure GraphStorm to co-train LM and GNN models.</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>All commands below should be run in a GraphStorm Docker container. Please refer to the <a class="reference internal" href="../install/env-setup.html#setup"><span class="std std-ref">GraphStorm Docker environment setup</span></a> to prepare your environment.</p>
</div>
</section>
<section id="prepare-raw-data">
<h1>Prepare Raw Data<a class="headerlink" href="#prepare-raw-data" title="Permalink to this heading">#</a></h1>
<p>This tutorial will use the same ACM data as the <a class="reference internal" href="../tutorials/own-data.html#use-own-data"><span class="std std-ref">Use Your Own Data</span></a> tutorial to demonstrate how to prepare text as node features.</p>
<p>First go the <code class="docutils literal notranslate"><span class="pre">/graphstorm/examples/</span></code> folder.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>/graphstorm/examples
</pre></div>
</div>
<p>Then run the command to create the ACM data with the required <code class="docutils literal notranslate"><span class="pre">raw_w_text</span></code> format.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python3<span class="w"> </span>-m<span class="w"> </span>/graphstorm/examples/acm_data.py<span class="w"> </span>--output-path<span class="w"> </span>/tmp/acm_raw<span class="w"> </span>--output-type<span class="w"> </span>raw_w_text
</pre></div>
</div>
<p>Once succeeded, the command will create a set of folders and files under the <code class="docutils literal notranslate"><span class="pre">/tmp/acm_raw/</span></code> folder same as the <a class="reference internal" href="../tutorials/own-data.html#acm-raw-data-output"><span class="std std-ref">outputs</span></a> in the <a class="reference internal" href="../tutorials/own-data.html#use-own-data"><span class="std std-ref">Use Your Own Data</span></a> tutorial. But the contents of the <code class="docutils literal notranslate"><span class="pre">config.json</span></code> have a few extra lines that list the text feature columns and how to process them during graph contruction.</p>
<p>The below snippet show the <code class="docutils literal notranslate"><span class="pre">author</span></code> node’s information. It shows the “<strong>text</strong>” column contains text features, and it require the GraphStorm graph contruction tool to use a HuggingFace BERT model, named <code class="docutils literal notranslate"><span class="pre">bert-base-uncased</span></code>, to tokenize these text features during construction.</p>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="nt">&quot;nodes&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span>
<span class="w">    </span><span class="p">{</span>
<span class="w">        </span><span class="nt">&quot;node_type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;author&quot;</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;format&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="nt">&quot;name&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;parquet&quot;</span>
<span class="w">        </span><span class="p">},</span>
<span class="w">        </span><span class="nt">&quot;files&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span>
<span class="w">            </span><span class="s2">&quot;/tmp/acm_raw/nodes/author.parquet&quot;</span>
<span class="w">        </span><span class="p">],</span>
<span class="w">        </span><span class="nt">&quot;node_id_col&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;node_id&quot;</span><span class="p">,</span>
<span class="w">        </span><span class="nt">&quot;features&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span>
<span class="w">            </span><span class="p">{</span>
<span class="w">                </span><span class="nt">&quot;feature_col&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;feat&quot;</span><span class="p">,</span>
<span class="w">                </span><span class="nt">&quot;feature_name&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;feat&quot;</span>
<span class="w">            </span><span class="p">},</span>
<span class="w">            </span><span class="p">{</span>
<span class="w">                </span><span class="nt">&quot;feature_col&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;text&quot;</span><span class="p">,</span>
<span class="w">                </span><span class="nt">&quot;feature_name&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;text&quot;</span><span class="p">,</span>
<span class="w">                </span><span class="nt">&quot;transform&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">                    </span><span class="nt">&quot;name&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;tokenize_hf&quot;</span><span class="p">,</span>
<span class="w">                    </span><span class="nt">&quot;bert_model&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;bert-base-uncased&quot;</span><span class="p">,</span>
<span class="w">                    </span><span class="nt">&quot;max_seq_length&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">16</span>
<span class="w">                </span><span class="p">}</span>
<span class="w">            </span><span class="p">}</span>
<span class="w">        </span><span class="p">]</span>
<span class="w">    </span><span class="p">},</span>
</pre></div>
</div>
</section>
<section id="construct-graph">
<h1>Construct Graph<a class="headerlink" href="#construct-graph" title="Permalink to this heading">#</a></h1>
<p>Then we use the graph construction tool to process the ACM raw data with the following command for GraphStorm model training.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python3<span class="w"> </span>-m<span class="w"> </span>graphstorm.gconstruct.construct_graph<span class="w"> </span><span class="se">\</span>
<span class="w">           </span>--conf-file<span class="w"> </span>/tmp/acm_raw/config.json<span class="w"> </span><span class="se">\</span>
<span class="w">           </span>--output-dir<span class="w"> </span>/tmp/acm_nc<span class="w"> </span><span class="se">\</span>
<span class="w">           </span>--num-parts<span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">           </span>--graph-name<span class="w"> </span>acm
</pre></div>
</div>
<p>Outcomes of this command are also same as the <a class="reference internal" href="../tutorials/own-data.html#output-graph-construction"><span class="std std-ref">Outputs of Graph Construction</span></a>. But users may notice that the <code class="docutils literal notranslate"><span class="pre">paper</span></code>, <code class="docutils literal notranslate"><span class="pre">author</span></code>, and <code class="docutils literal notranslate"><span class="pre">subject</span></code> nodes all have three additional features, named <code class="docutils literal notranslate"><span class="pre">input_ids</span></code>,``attention_mask``, and <code class="docutils literal notranslate"><span class="pre">token_type_ids</span></code>, which are generated by the BERT tokenizer.</p>
</section>
<section id="graphstorm-language-model-configuration">
<h1>GraphStorm Language Model Configuration<a class="headerlink" href="#graphstorm-language-model-configuration" title="Permalink to this heading">#</a></h1>
<p>Users can set up language model in GraphStorm’s configuration YAML file. Below is an example of such configuration for the ACM data. The full configuration YAML file, <a class="reference external" href="https://github.com/awslabs/graphstorm/blob/main/examples/use_your_own_data/acm_lm_nc.yaml">acm_lm_nc.yaml</a>, is located under GraphStorm’s <code class="docutils literal notranslate"><span class="pre">examples/use_your_own_data</span></code> folder. .</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">lm_model</span><span class="p">:</span>
<span class="nt">node_lm_models</span><span class="p">:</span>
<span class="w">  </span><span class="p p-Indicator">-</span>
<span class="w">    </span><span class="nt">lm_type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">bert</span>
<span class="w">    </span><span class="nt">model_name</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;bert-base-uncased&quot;</span>
<span class="w">    </span><span class="nt">gradient_checkpoint</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="w">    </span><span class="nt">node_types</span><span class="p">:</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">paper</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">author</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">subject</span>
</pre></div>
</div>
<p>The current version of GraphStorm supports pre-trained BERT models from HuggingFace reposity on nodes only. Users can choose any <a class="reference external" href="https://huggingface.co/models">HuggingFace BERT models</a>. But the value of <code class="docutils literal notranslate"><span class="pre">model_name</span></code> <strong>MUST</strong> be the same as the one specified in the raw data JSON file’s <code class="docutils literal notranslate"><span class="pre">bert_model</span></code> field. Here in the example, it is the <code class="docutils literal notranslate"><span class="pre">bert-base-uncased</span></code> model.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">node_type</span></code> field list the types of nodes that have tokenized text features. In this ACM example, all three types of nodes have tokenized text features, which are all list in the configuration YAML file.</p>
</section>
<section id="launch-graphstorm-trainig-without-fine-tuning-bert-models">
<h1>Launch GraphStorm Trainig without Fine-tuning BERT Models<a class="headerlink" href="#launch-graphstorm-trainig-without-fine-tuning-bert-models" title="Permalink to this heading">#</a></h1>
<p>With the above GraphStorm configuration YAML file, we can launch GraphStorm model training with the same commands as in the <a class="reference internal" href="../tutorials/own-data.html#launch-training-oyog"><span class="std std-ref">Step 3: Launch training script on your own graphs</span></a>.</p>
<p>First, we create the <code class="docutils literal notranslate"><span class="pre">ip_list.txt</span></code> file for the standalone mode.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>touch<span class="w"> </span>/tmp/ip_list.txt
<span class="nb">echo</span><span class="w"> </span><span class="m">127</span>.0.0.1<span class="w"> </span>&gt;<span class="w"> </span>/tmp/ip_list.txt
</pre></div>
</div>
<p>Then, the launch command is almost the same except that the configuration file is the <code class="docutils literal notranslate"><span class="pre">acm_lm_nc.yaml</span></code>, which contains the language model configurations.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python3<span class="w"> </span>-m<span class="w"> </span>graphstorm.run.gs_node_classification<span class="w"> </span><span class="se">\</span>
<span class="w">        </span>--workspace<span class="w"> </span>/tmp<span class="w"> </span><span class="se">\</span>
<span class="w">        </span>--part-config<span class="w"> </span>/tmp/acm_nc/acm.json<span class="w"> </span><span class="se">\</span>
<span class="w">        </span>--ip-config<span class="w"> </span>/tmp/ip_list.txt<span class="w"> </span><span class="se">\</span>
<span class="w">        </span>--num-trainers<span class="w"> </span><span class="m">4</span><span class="w"> </span><span class="se">\</span>
<span class="w">        </span>--num-servers<span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">        </span>--num-samplers<span class="w"> </span><span class="m">0</span><span class="w"> </span><span class="se">\</span>
<span class="w">        </span>--ssh-port<span class="w"> </span><span class="m">2222</span><span class="w"> </span><span class="se">\</span>
<span class="w">        </span>--cf<span class="w"> </span>/tmp/acm_lm_nc.yaml<span class="w"> </span><span class="se">\</span>
<span class="w">        </span>--save-model-path<span class="w"> </span>/tmp/acm_nc/models<span class="w"> </span><span class="se">\</span>
<span class="w">        </span>--node-feat-name<span class="w"> </span>paper:feat<span class="w"> </span>author:feat<span class="w"> </span>subject:feat
</pre></div>
</div>
<p>In the training process, GraphStorm will first use the specified BERT model to compute the text embeddings in the specified node types. And then the text embeddings and other node features are concatenated together as the input node feature for GNN models training.</p>
</section>
<section id="launch-graphstorm-trainig-for-both-bert-and-gnn-models">
<h1>Launch GraphStorm Trainig for both BERT and GNN Models<a class="headerlink" href="#launch-graphstorm-trainig-for-both-bert-and-gnn-models" title="Permalink to this heading">#</a></h1>
<p>To co-train BERT and GNN models, we need to add one more argument, the <code class="docutils literal notranslate"><span class="pre">--lm-train-nodes</span></code>, in either the launch command or configuration YAML file. Below command sets this argument in the launch command.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python3<span class="w"> </span>-m<span class="w"> </span>graphstorm.run.gs_node_classification<span class="w"> </span><span class="se">\</span>
<span class="w">        </span>--workspace<span class="w"> </span>/tmp<span class="w"> </span><span class="se">\</span>
<span class="w">        </span>--part-config<span class="w"> </span>/tmp/acm_nc/acm.json<span class="w"> </span><span class="se">\</span>
<span class="w">        </span>--ip-config<span class="w"> </span>/tmp/ip_list.txt<span class="w"> </span><span class="se">\</span>
<span class="w">        </span>--num-trainers<span class="w"> </span><span class="m">4</span><span class="w"> </span><span class="se">\</span>
<span class="w">        </span>--num-servers<span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">        </span>--num-samplers<span class="w"> </span><span class="m">0</span><span class="w"> </span><span class="se">\</span>
<span class="w">        </span>--ssh-port<span class="w"> </span><span class="m">2222</span><span class="w"> </span><span class="se">\</span>
<span class="w">        </span>--cf<span class="w"> </span>/tmp/acm_lm_nc.yaml<span class="w"> </span><span class="se">\</span>
<span class="w">        </span>--save-model-path<span class="w"> </span>/tmp/acm_nc/models<span class="w"> </span><span class="se">\</span>
<span class="w">        </span>--node-feat-name<span class="w"> </span>paper:feat<span class="w"> </span>author:feat<span class="w"> </span>subject:feat<span class="w"> </span><span class="se">\</span>
<span class="w">        </span>--lm-train-nodes<span class="w"> </span><span class="m">10</span>
</pre></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">--lm-train-nodes</span></code> argument determines how many nodes will be used to train the BERT models. Because the BERT models are normally large, training of them will consume many memories. If use all nodes to co-train BERT and GNN models, it could cause GPU out of memory (OOM) errors. Use a smaller number for the <code class="docutils literal notranslate"><span class="pre">--lm-train-nodes</span></code> could reduce the chances of OOM errors.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>It will take longer time to co-train BERT and GNN models compared to not doing co-train.</p>
</div>
</section>
<section id="only-use-bert-models">
<h1>Only Use BERT Models<a class="headerlink" href="#only-use-bert-models" title="Permalink to this heading">#</a></h1>
<p>GraphStorm also allows users to only use BERT models to perform graph tasks. We can add another argument, <code class="docutils literal notranslate"><span class="pre">--lm-encoder-only</span></code>, to control whether only use BERT models or not.</p>
<p>The command below use BERT model only without fine-tuning the model.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python3<span class="w"> </span>-m<span class="w"> </span>graphstorm.run.gs_node_classification<span class="w"> </span><span class="se">\</span>
<span class="w">        </span>--workspace<span class="w"> </span>/tmp<span class="w"> </span><span class="se">\</span>
<span class="w">        </span>--part-config<span class="w"> </span>/tmp/acm_nc/acm.json<span class="w"> </span><span class="se">\</span>
<span class="w">        </span>--ip-config<span class="w"> </span>/tmp/ip_list.txt<span class="w"> </span><span class="se">\</span>
<span class="w">        </span>--num-trainers<span class="w"> </span><span class="m">4</span><span class="w"> </span><span class="se">\</span>
<span class="w">        </span>--num-servers<span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">        </span>--num-samplers<span class="w"> </span><span class="m">0</span><span class="w"> </span><span class="se">\</span>
<span class="w">        </span>--ssh-port<span class="w"> </span><span class="m">2222</span><span class="w"> </span><span class="se">\</span>
<span class="w">        </span>--cf<span class="w"> </span>/tmp/acm_lm_nc.yaml<span class="w"> </span><span class="se">\</span>
<span class="w">        </span>--save-model-path<span class="w"> </span>/tmp/acm_nc/models<span class="w"> </span><span class="se">\</span>
<span class="w">        </span>--node-feat-name<span class="w"> </span>paper:feat<span class="w"> </span>author:feat<span class="w"> </span>subject:feat<span class="w"> </span><span class="se">\</span>
<span class="w">        </span>--lm-encoder-only
</pre></div>
</div>
<p>If users want to fine tune the BERT model only, just add the <code class="docutils literal notranslate"><span class="pre">--lm-train-nodes</span></code> argument as the command below:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python3<span class="w"> </span>-m<span class="w"> </span>graphstorm.run.gs_node_classification<span class="w"> </span><span class="se">\</span>
<span class="w">        </span>--workspace<span class="w"> </span>/tmp<span class="w"> </span><span class="se">\</span>
<span class="w">        </span>--part-config<span class="w"> </span>/tmp/acm_nc/acm.json<span class="w"> </span><span class="se">\</span>
<span class="w">        </span>--ip-config<span class="w"> </span>/tmp/ip_list.txt<span class="w"> </span><span class="se">\</span>
<span class="w">        </span>--num-trainers<span class="w"> </span><span class="m">4</span><span class="w"> </span><span class="se">\</span>
<span class="w">        </span>--num-servers<span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">        </span>--num-samplers<span class="w"> </span><span class="m">0</span><span class="w"> </span><span class="se">\</span>
<span class="w">        </span>--ssh-port<span class="w"> </span><span class="m">2222</span><span class="w"> </span><span class="se">\</span>
<span class="w">        </span>--cf<span class="w"> </span>/tmp/acm_lm_nc.yaml<span class="w"> </span><span class="se">\</span>
<span class="w">        </span>--save-model-path<span class="w"> </span>/tmp/acm_nc/models<span class="w"> </span><span class="se">\</span>
<span class="w">        </span>--node-feat-name<span class="w"> </span>paper:feat<span class="w"> </span>author:feat<span class="w"> </span>subject:feat<span class="w"> </span><span class="se">\</span>
<span class="w">        </span>--lm-encoder-only<span class="w"> </span><span class="se">\</span>
<span class="w">        </span>--lm-train-nodes<span class="w"> </span><span class="m">10</span>
</pre></div>
</div>
</section>

        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          
          <a class="prev-page" href="own-models.html">
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
              <div class="page-info">
                <div class="context">
                  <span>Previous</span>
                </div>
                
                <div class="title">Use Your Own Models</div>
                
              </div>
            </a>
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; 2023, AGML team
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer no-toc">
      
      
      
    </aside>
  </div>
</div><script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/sphinx_highlight.js"></script>
    <script src="../_static/scripts/furo.js"></script>
    </body>
</html>