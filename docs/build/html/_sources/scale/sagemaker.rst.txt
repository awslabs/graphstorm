.. _distributed-sagemaker:

Use GraphStorm based on SageMaker
===================================
GraphStorm can run on Amazon Sagemaker to leverage SageMaker's ML DevOps capabilities.

Prerequisites
-----------------
In order to use GraphStorm in Amazon SageMaker, users need to have AWS access to the following AWS services.

- SageMaker service. Please refer to `Anmazon SageMaker service <https://aws.amazon.com/pm/sagemaker/>`_ for how to get access to Amazon SageMaker.
- Amazon ECR. Please refer to `Amazon Elastic Container Registry service <https://aws.amazon.com/ecr/>`_ for how to get access to Amazon ECR.
- S3 service. Please refer to `Amazon S3 service <https://aws.amazon.com/s3/>`_ for how to get access to Amazon S3.
- SageMaker Framework Containers. Please follow `AWS Deep Learning Containers guideline <https://github.com/aws/deep-learning-containers>`_ to get access to the image.
- Amazon EC2 (optional). Please refer to `Amazon EC2 service <https://aws.amazon.com/ec2/>`_ for how to get access to Amazon ECR.

Setup GraphStorm SageMaker Docker Repository
----------------------------------------------
GraphStorm uses SageMaker's "Bring Your Own Container (BYOC)" mode. Therefore, before launch GraphStorm on SageMaker, there are two steps required to set up a GraphStorm SageMaker Docker repository.

Step 1: Build a SageMaker compatible Docker image
...................................................

.. note::
    * Please make sure your account has AWS access key (AK) and security access key (SK) configured to authenticate access to AWS services.
    * For more details of Amazon ECR operation via CLI, users can refer to `Using Amazon ECR with the AWS CLI document <https://docs.aws.amazon.com/AmazonECR/latest/userguide/getting-started-cli.html>`_.

First, in either a Linux EC2 instance or a SageMaker Notebook Linux instance, configure a Docker environment by following the `Docker documentent <https://docs.docker.com/get-docker/>`_ suggestions.

In order to use the SageMaker base Docker image, users need to authenticate to use SageMaker images with the following command.

.. code-block:: bash

    aws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin 763104351884.dkr.ecr.us-east-1.amazonaws.com

Then, clone GraphStorm source code, and build a GraphStorm SageMaker compatible Docker image from source with commands:

.. code-block:: bash

    git clone https://github.com/awslabs/graphstorm.git
    
    cd /path-to-graphstorm/docker/

    bash /path-to-graphstorm/docker/build_docker_sagemaker.sh /path-to-graphstorm/ <DOCKER_NAME> <DOCKER_TAG>

The ``build_docker_sagemaker.sh`` command take three arguments:

1. **path-to-graphstorm** (**required**), is the absolute path of the "graphstorm" folder, where you clone and download the GraphStorm source code. For example, the path could be ``/code/graphstorm``.
2. **DOCKER_NAME** (optional), is the assigned name of the to be built Docker image. Default is ``graphstorm``.

.. note::
    In order to upload the GraphStorm SageMaker Docker image to ECR, users need to define the <DOCKER_NAME> to include the ECR URI string, <AWS_ACCOUNT_ID>.dkr.ecr.<REGION>.amazonaws.com, e.g., ``911734752298.dkr.ecr.us-east-1.amazonaws.com/graphstorm``.

3. **DOCKER_TAG** (optional), is the assigned tag name of the to be built docker image. Default is ``sm``.

Once the ``build_docker_sagemaker.sh`` command completes successfully. There will be a Docker image, named ``<DOCKER_NAME>:<DOCKER_TAG>``, such as ``911734752298.dkr.ecr.us-east-1.amazonaws.com/graphstorm:sm``, in the local repository.

Step 2: Upload the Docker Image to ECR
........................................
Because SageMaker relies on Amazon ECR to access customers' own Docker images, users need to upload the Docker image built in the Step 1 to their own ECR repository.

The following command will authenticate the user account to access to user's ECR repository via AWS CLI.

.. code-block:: bash

    aws ecr get-login-password --region <REGION> | docker login --username AWS --password-stdin <AWS_ACCOUNT_ID>.dkr.ecr.<REGION>.amazonaws.com

Please replace the `<REGION>` and `<AWS_ACCOUNT_ID>` with your own account information and be consistent with the values used in the Step 1.

In addition, users need to create an ECR repository at the specified `<REGION>` with the name as `<DOCKER_NAME>` **WITHOUT** the ECR URI string, e.g., ``graphstorm``.

And then use below command to push the built GraphStorm Docker image to users' own ECR repository.

.. code-block:: bash

    docker push <DOCKER_NAME>:<DOCKER_TAG>

Please replace the `<DOCKER_NAME>` and `<DOCKER_TAG>` with the actual Docker image name, e.g., ``911734752298.dkr.ecr.us-east-1.amazonaws.com/graphstorm:sm``.

Run GraphStorm on SageMaker
----------------------------
There are two ways to run GraphStorm on SageMaker.

* Run with Amazon SageMaker service. In this way, users will use GraphStorm's tools to submit SageMaker API calls, which will request SageMaker services to start new SageMaker training or inference instances that run GraphStorm code. Users can submit the API calls in a cheap EC2 instance or a SageMaker Notebook instance without GPUs (e.g., C5.xlarge). This is the formal way to run GraphStorm experiments on large graphs and to deploy GraphStorm on SageMaker for production.
* Run with Docker composes in local environment. In this way, users do not call the SageMaker service, but use Docker compose to run SageMaker locally in an EC2 instance or a SageMaker Notebook instance that has GPUs. This is mainly for model developers and testers to simulate running GraphStorm on SageMaker.

Run with Amazon SageMaker service
...................................
To call Amazon SageMaker service, users should set up an instance with SageMaker library installed and GraphStorm's SageMaker tools copied.

1. Use the below command to install SageMaker.

.. code-block:: bash

    pip install sagemaker

2. copy GraphStorm SageMaker tools. Users can clone the GraphStorm repository with the following command, or copy the `sagemaker folder <https://github.com/awslabs/graphstorm/tree/main/sagemaker>`_ to the instance.

.. code-block:: bash

    git clone https://github.com/awslabs/graphstorm.git

Prepare graph data
`````````````````````
Unlike GraphStorm's :ref:`Standalone mode<quick-start-standalone>` and :ref:`the Distributed mode<distributed-cluster>` that rely on local disk or shared file system to store the partitioned graph, SageMaker uses Amaonz S3 as the shared data storage to distribute partitioned graphs and the configuration YAML file.

This tutorial uses the same three-partition OGB-MAG graph and the link prediction task as those introduced in the :ref:`Partition a Graph<partition-a-graph>` section of the :ref:`Use GraphStorm in a Distributed Cluster<distributed-cluster>` tutorial. After generate the partitioned OGB-MAG graphs, use the following commands to upload them and the GraphStorm configuration YAML file to an S3 bucket.

.. code-block:: bash

    aws s3 cp --recursive /data/ogbn_mag_lp_3p s3://<PATH_TO_DATA>/ogbn_mag_lp_3p
    aws s3 cp /graphstorm/training_scripts/gsgnn_lp/mag_lp.yaml s3://<PATH_TO_TRAINING_CONFIG>/mag_lp.yaml

Please replace the `<PATH_TO_DATA>` and `<PATH_TO_TRAINING_CONFIG>` with your own S3 bucket URI.

Launch training 
```````````````````
Launch GraphStorm training on SageMaker is similar as launch in the :ref:`Standalone mode<quick-start-standalone>` and :ref:`the Distributed mode<distributed-cluster>`, except for three diffences:
* The launch command is under the ``graphstorm/sagemaker`` folder, and
* Users need to provide AWS service-related information in the command.
* All paths for saving models, embeddings, and predict results should be an S3 location specified through the ``--model-artifact-s3`` argument.

.. note::
    Before running SageMaker tasks, login to the ECR where the image is present.
    .. code-block:: bash

        aws ecr get-login-password --region <REGION> | docker login --username AWS --password-stdin <AWS_ACCOUNT_ID>.dkr.ecr.<REGION>.amazonaws.com

    Please replace the `<REGION>` and `<AWS_ACCOUNT_ID>` with your own account information and be consistent with the values used in the Step 1.

Users can use the following commands to launch a GraphStorm link prediction training job with the OGB-MAG graph.

.. code-block:: bash

    cd /path-to-graphstorm/sagemaker/
    
    python3 launch/launch_train.py \
        --image-url <AMAZON_ECR_IMAGE_URI> \
        --region <REGION> \
        --entry-point run/train_entry.py \
        --role <ROLE_ARN> \
        --instance-count 3 \
        --graph-data-s3 s3://<PATH_TO_DATA>/ogbn_mag_lp_3p \
        --yaml-s3 s3://<PATH_TO_TRAINING_CONFIG>/mag_lp.yaml \
        --model-artifact-s3 s3://<PATH_TO_SAVE_TRAINED_MODEL>/ \
        --graph-name ogbn-mag \
        --task-type link_prediction \
        --lp-decoder-type dot_product \
        --num-layers 1 \
        --hidden-size 128 \
        --backend gloo \
        --batch-size 128 \

Please replace the `<AMAZON_ECR_IMAGE_URI>` with the `<DOCKER_NAME>:<DOCKER_TAG>` that used in the Step 2, e.g., ``911734752298.dkr.ecr.us-east-1.amazonaws.com/graphstorm-sagemaker-oss:v0.1``, replace the `<REGION>` with the region where ECR image repository is located, e.g., ``us-east-1``, and replace the `<ROLE_ARN>` with your AWS account ARN that has SageMaker execution role, e.g., ``"arn:aws:iam::<ACCOUNT_ID>:role/service-role/AmazonSageMaker-ExecutionRole-20220627T143571"``.

Because we use three-partition OGB-MAG graph, we need to set the ``--instance-count`` to 3 in this command.

The trained model artifact will be stored in the S3 address provided through ``--model-artifact-s3``. You can use following command to check the model artifacts:

.. code-block:: bash

    aws s3 ls s3://<PATH_TO_SAVE_TRAINED_MODEL>/

.. note:: the ``save_embed_path`` and ``save_prediction_path`` **MUST** be disabled, i.e., set to 'None' when using SageMaker. They only work with local disk (in the Standalone mode) or shared file system (in the Distributed mode).

Launch inference
.................
