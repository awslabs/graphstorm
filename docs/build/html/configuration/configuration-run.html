<!doctype html>
<html class="no-js" lang="en">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />
<link rel="index" title="Index" href="../genindex.html" /><link rel="search" title="Search" href="../search.html" /><link rel="next" title="Use GraphStorm in a Distributed Cluster" href="../scale/distributed.html" /><link rel="prev" title="Graph Partition" href="configuration-partition.html" />

    <!-- Generated with Sphinx 6.1.3 and Furo 2023.03.27 -->
        <title>Training and Inference - GraphStorm 0.1 documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo.css?digest=fad236701ea90a88636c2a8c73b44ae642ed2a53" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo-extensions.css?digest=30d1aed668e5c3a91c3e3bf6a60b675221979f0e" />
    
    


<style>
  body {
    --color-code-background: #f8f8f8;
  --color-code-foreground: black;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
      }
    }
  }
</style></head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-half" viewBox="0 0 24 24">
    <title>Auto light/dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-shadow">
      <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
      <circle cx="12" cy="12" r="9" />
      <path d="M13 12h5" />
      <path d="M13 15h4" />
      <path d="M13 18h1" />
      <path d="M13 9h4" />
      <path d="M13 6h1" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation">
  <div class="visually-hidden">Hide navigation sidebar</div>
</label>
<label class="overlay toc-overlay" for="__toc">
  <div class="visually-hidden">Hide table of contents sidebar</div>
</label>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <div class="visually-hidden">Toggle site navigation sidebar</div>
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="../index.html"><div class="brand">GraphStorm 0.1 documentation</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle">
          <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
          <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon" for="__toc">
        <div class="visually-hidden">Toggle table of contents sidebar</div>
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand" href="../index.html">
  
  
  <span class="sidebar-brand-text">GraphStorm 0.1 documentation</span>
  
</a><form class="sidebar-search-container" method="get" action="../search.html" role="search">
  <input class="sidebar-search" placeholder="Search" name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <p class="caption" role="heading"><span class="caption-text">Get Started</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../install/env-setup.html">Environment Setup</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/quick-start.html">Standalone Mode Quick Start Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/own-data.html">Use Your Own Data Tutorial</a></li>
<li class="toctree-l1 current has-children"><a class="reference internal" href="index.html">GraphStorm Configurations</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" role="switch" type="checkbox"/><label for="toctree-checkbox-1"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="configuration-gconstruction.html">Graph Construction</a></li>
<li class="toctree-l2"><a class="reference internal" href="configuration-partition.html">Graph Partition</a></li>
<li class="toctree-l2 current current-page"><a class="current reference internal" href="#">Training and Inference</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Scale to Giant Graphs</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../scale/distributed.html">Use GraphStorm in a Distributed Cluster</a></li>
<li class="toctree-l1"><a class="reference internal" href="../scale/sagemaker.html">Use GraphStorm on SageMaker</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Advanced Topics</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../advanced/own-models.html">Use Your Own Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/language-models.html">Use Text as Node Features</a></li>
</ul>

</div>
</div>

      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          
<div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle">
              <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
              <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon" for="__toc">
            <div class="visually-hidden">Toggle table of contents sidebar</div>
            <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
          </label>
        </div>
        <article role="main">
          <section id="training-and-inference">
<span id="configurations-run"></span><h1>Training and Inference<a class="headerlink" href="#training-and-inference" title="Permalink to this heading">#</a></h1>
<p>GraphStorm provides dozens of configurable parameters for users to control their training and inference tasks. This document provides detailed description of each configurable parameter. You can use YAML config file to define these parameters or you can use command line arguments to define and update these parameters. Specifically, GraphStorm parses yaml config file first. Then it parses arguments to overwrite parameters defined in the yaml file or add new parameters.</p>
<section id="launch-arguments">
<h2>Launch Arguments<a class="headerlink" href="#launch-arguments" title="Permalink to this heading">#</a></h2>
<p>GraphStorm’s <a class="reference external" href="https://github.com/awslabs/graphstorm/blob/main/python/graphstorm/run/launch.py">graphstorm.run.launch</a> command has a set of parameters to control the launch behavior of training and inference.</p>
<ul>
<li><p><strong>workspace</strong>: the folder where launch command assume all artifacts were saved. If the other parameters’ file paths are relative paths, launch command will consider these files in the workspace.</p></li>
<li><p><strong>part-config</strong>: (<strong>Required</strong>) Path to a file containing graph partition configuration. The graph partition is generated by GraphStorm Partition tools. <strong>HINT</strong>: Use absolute path to avoid any path related problems. Otherwise, the file should be in workspace.</p></li>
<li><p><strong>ip-config</strong>: (<strong>Required</strong>) Path to a file containing IPs of instances in a distributed training/inference cluster. In the ip config file, each line stores one IP. <strong>HINT</strong>: Use absolute path to avoid any path related problems. Otherwise, the file should be in workspace.</p></li>
<li><p><strong>num-trainers</strong>: The number of trainer processes per machine. Should &gt;0.</p></li>
<li><p><strong>num-servers</strong>: The number of server processes per machine. Should &gt;0.</p></li>
<li><p><strong>num-samplers</strong>: The number of sampler processes per trainer process. Should &gt;=0.</p></li>
<li><p><strong>num-server-threads</strong>: The number of OMP threads in the server process. It should be small if server processes and trainer processes run on the same machine. Should &gt;0. By default, it is 1.</p></li>
<li><p><strong>ssh-port</strong>: SSH port used by the host node to communicate with the other nodes in the cluster.</p></li>
<li><p><strong>ssh-username</strong>: Optional. When issuing commands (via ssh) to cluster, use the provided username in the ssh command.</p></li>
<li><p><strong>graph-format</strong>: The format of the graph structure of each partition. The allowed formats are csr, csc and coo. A user can specify multiple formats, separated by “,”. For example, the graph format is “csr,csc”.</p></li>
<li><p><strong>extra-envs</strong>: Extra environment parameters need to be set. For example, you can set the LD_LIBRARY_PATH and NCCL_DEBUG by adding:</p>
<blockquote>
<div><ul class="simple">
<li><p>–extra_envs LD_LIBRARY_PATH=/usr/local/cuda/lib64:$LD_LIBRARY_PATH</p></li>
<li><p>–extra-envs LD_LIBRARY_PATH=/usr/local/cuda/lib64:$LD_LIBRARY_PATH</p></li>
<li><p>NCCL_DEBUG=INFO</p></li>
</ul>
</div></blockquote>
</li>
<li><p><strong>lm-encoder-only</strong>: Indicate that the model is using language model + decoder only. model. No GNN is involved, only graph structure.</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Below configurations can be set either in a YAML configuraiton file or be added as arguments of launch command.</p>
</div>
</section>
<section id="environment-configurations">
<h2>Environment Configurations<a class="headerlink" href="#environment-configurations" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><dl class="simple">
<dt><strong>backend</strong>: (<strong>Required</strong>) PyTorch distributed backend, the suggested backend is gloo. Support backends include gloo and nccl</dt><dd><ul>
<li><p>Yaml: <code class="docutils literal notranslate"><span class="pre">backend:</span> <span class="pre">gloo</span></code></p></li>
<li><p>Argument: <code class="docutils literal notranslate"><span class="pre">--backend</span> <span class="pre">gloo</span></code></p></li>
<li><p>Default value: <code class="docutils literal notranslate"><span class="pre">gloo</span></code></p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>verbose</strong>: Set true to print more execution information</dt><dd><ul>
<li><p>Yaml: <code class="docutils literal notranslate"><span class="pre">verbose:</span> <span class="pre">false</span></code></p></li>
<li><p>Argument: <code class="docutils literal notranslate"><span class="pre">--verbose</span> <span class="pre">false</span></code></p></li>
<li><p>Default value: <code class="docutils literal notranslate"><span class="pre">false</span></code></p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</section>
<section id="model-configurations">
<h2>Model Configurations<a class="headerlink" href="#model-configurations" title="Permalink to this heading">#</a></h2>
<p>GraphStorm provides a set of parameters to config the GNN model structure (input layer, gnn layer, decoder layer, etc)</p>
<ul>
<li><dl class="simple">
<dt><strong>model_encoder_type</strong>: (<strong>Required</strong>) Graph encoder model used to encode graph data. It can be rgat or rgcn.</dt><dd><ul class="simple">
<li><p>Yaml: <code class="docutils literal notranslate"><span class="pre">model_encoder_type:</span> <span class="pre">rgcn</span></code></p></li>
<li><p>Argument: <code class="docutils literal notranslate"><span class="pre">--model-encoder-type</span> <span class="pre">rgcn</span></code></p></li>
<li><p>Default value: This parameter must be provided by user.</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl>
<dt><strong>node_feat_name</strong>: User defined feature name. It accepts two formats: a) <cite>fname</cite>, if a node has node features, the corresponding feature name will be fname; b) <cite>ntype0:feat0 ntype1:featA …</cite>, different node types have different node feature name(s). In the example, “ntype0” has a node feature named “feat0” and “ntype1” has a node feature named “featA”. Note: Characters <cite>:</cite> and ` ` are not allowed to be used in node feature names.  And in Yaml format, need to put each node’s feature in a separated line that starts with a hyphon.</dt><dd><ul>
<li><dl>
<dt>Yaml: <code class="docutils literal notranslate"><span class="pre">node_feat_name:</span></code></dt><dd><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">-</span> <span class="pre">&quot;ntype1:featA&quot;</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">-</span> <span class="pre">&quot;ntype0:feat0&quot;</span></code></div>
</div>
</dd>
</dl>
</li>
<li><p>Argument: <code class="docutils literal notranslate"><span class="pre">--node-feat-name</span> <span class="pre">&quot;ntype0:feat0</span> <span class="pre">ntype1:featA&quot;</span></code></p></li>
<li><p>Default value: If not provided, there will be no node features used by GraphStorm even graphs have node features attached.</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>num_layers</strong>: Number of GNN layers. Must be an integer larger than 0 if given. By default, it is set to 0, which means no GNN layers.</dt><dd><ul class="simple">
<li><p>Yaml: <code class="docutils literal notranslate"><span class="pre">num_layers:</span> <span class="pre">2</span></code></p></li>
<li><p>Argument: <code class="docutils literal notranslate"><span class="pre">--num-layers</span> <span class="pre">2</span></code></p></li>
<li><p>Default value: <code class="docutils literal notranslate"><span class="pre">0</span></code></p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>hidden_size</strong>: (<strong>Required</strong>) The dimension of hidden GNN layers. Must be an integer larger than 0. Currently, each GNN layer has the same hidden dimension.</dt><dd><ul class="simple">
<li><p>Yaml: <code class="docutils literal notranslate"><span class="pre">hidden_size:</span> <span class="pre">128</span></code></p></li>
<li><p>Argument: <code class="docutils literal notranslate"><span class="pre">--hidden-size</span> <span class="pre">128</span></code></p></li>
<li><p>Default value: This parameter must be provided by user.</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>use_self_loop</strong>: Set true include self feature as a special relation in relational GNN models. Used by built-in RGCN and RGAT model.</dt><dd><ul class="simple">
<li><p>Yaml: <code class="docutils literal notranslate"><span class="pre">use_self_loop:</span> <span class="pre">false</span></code></p></li>
<li><p>Argument: <code class="docutils literal notranslate"><span class="pre">--use-self-loop</span> <span class="pre">false</span></code></p></li>
<li><p>Default value: <code class="docutils literal notranslate"><span class="pre">true</span></code></p></li>
</ul>
</dd>
</dl>
</li>
</ul>
<section id="built-in-model-specific-configurations">
<h3>Built-in Model Specific Configurations<a class="headerlink" href="#built-in-model-specific-configurations" title="Permalink to this heading">#</a></h3>
<section id="rgcn">
<h4>RGCN<a class="headerlink" href="#rgcn" title="Permalink to this heading">#</a></h4>
<ul class="simple">
<li><dl class="simple">
<dt><strong>num_bases</strong>: Number of filter weight matrices. num_bases is used to reduce the overall parameters of a RGCN model. It allows weight metrics of different relation types to share parameters. Note: the number of relation types of the graph used in training must be divisible by num_bases. By default, num_bases is set to -1, which means weight metrics do not share parameters.</dt><dd><ul>
<li><p>Yaml: <code class="docutils literal notranslate"><span class="pre">num_bases:</span> <span class="pre">2</span></code></p></li>
<li><p>Argument: <code class="docutils literal notranslate"><span class="pre">--num-bases</span> <span class="pre">2</span></code></p></li>
<li><p>Default value: <code class="docutils literal notranslate"><span class="pre">-1</span></code></p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</section>
<section id="rgat">
<h4>RGAT<a class="headerlink" href="#rgat" title="Permalink to this heading">#</a></h4>
<ul class="simple">
<li><dl class="simple">
<dt><strong>num_heads</strong>: Number of attention heads.</dt><dd><ul>
<li><p>Yaml: <code class="docutils literal notranslate"><span class="pre">num_heads:</span> <span class="pre">8</span></code></p></li>
<li><p>Argument: <code class="docutils literal notranslate"><span class="pre">--num-heads</span> <span class="pre">8</span></code></p></li>
<li><p>Default value: <code class="docutils literal notranslate"><span class="pre">4</span></code></p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</section>
</section>
</section>
<section id="model-save-restore-configurations">
<h2>Model Save/Restore Configurations<a class="headerlink" href="#model-save-restore-configurations" title="Permalink to this heading">#</a></h2>
<p>GraphStorm provides a set of parameters to control how and where to save and restore models.</p>
<ul class="simple">
<li><dl class="simple">
<dt><strong>save_model_path</strong>: A path to save GraphStorm model parameters and the corresponding optimizer status. The saved model parameters can be used in inference or model fine-tuning. See restore_model_path for how to retrieve a saved model and restore_optimizer_path for how to retrieve optimizer status.</dt><dd><ul>
<li><p>Yaml: <code class="docutils literal notranslate"><span class="pre">save_model_path:</span> <span class="pre">/model/checkpoint/</span></code></p></li>
<li><p>Argument: <code class="docutils literal notranslate"><span class="pre">--save-model-path</span> <span class="pre">/model/checkpoint/</span></code></p></li>
<li><p>Default value: If not provide, models will not be saved.</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>save_embed_path</strong>: A path to save generated node embeddings.</dt><dd><ul>
<li><p>Yaml: <code class="docutils literal notranslate"><span class="pre">save_embed_path:</span> <span class="pre">/model/emb/</span></code></p></li>
<li><p>Argument: <code class="docutils literal notranslate"><span class="pre">--save-embed-path</span> <span class="pre">/model/emb/</span></code></p></li>
<li><p>Default value: If not provide, models will not be saved.</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>save_model_frequency</strong>: Number of iterations to save model once. By default, GraphStorm will save models at the end of each epoch if save_model_path is provided. A user can set a positive integer, e.g. <cite>N</cite>, to let GraphStorm save models every <cite>N`</cite> iterations (mini-batches).</dt><dd><ul>
<li><p>Yaml: <code class="docutils literal notranslate"><span class="pre">save_model_frequency:</span> <span class="pre">1000</span></code></p></li>
<li><p>Argument: <code class="docutils literal notranslate"><span class="pre">--save-model-frequency</span> <span class="pre">1000</span></code></p></li>
<li><p>Default value: <code class="docutils literal notranslate"><span class="pre">-1</span></code>. GraphStorm will not save models within an epoch.</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>topk_model_to_save</strong>: The number of top best GraphStorm model to save. By default, GraphStorm will keep all the saved models in disk, which will consume huge number of disk space. Users can set a positive integer, e.g. <cite>K</cite>, to let GraphStorm only save <cite>K`</cite> models with the best performance.</dt><dd><ul>
<li><p>Yaml: <code class="docutils literal notranslate"><span class="pre">topk_model_to_save:</span> <span class="pre">3</span></code></p></li>
<li><p>Argument: <code class="docutils literal notranslate"><span class="pre">--topk-model-to-save</span> <span class="pre">3</span></code></p></li>
<li><p>Default value: <code class="docutils literal notranslate"><span class="pre">0</span></code>. GraphStorm will save all the saved models in disk.</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>save_perf_results_path</strong>: Folder path to save performance results of model evaluation.</dt><dd><ul>
<li><p>Yaml: <code class="docutils literal notranslate"><span class="pre">save_perf_results_path:</span> <span class="pre">/model/results/</span></code></p></li>
<li><p>Argument: <code class="docutils literal notranslate"><span class="pre">--save-perf-results-path</span> <span class="pre">/model/results/</span></code></p></li>
<li><p>Default value: <code class="docutils literal notranslate"><span class="pre">None</span></code></p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>task_tracker</strong>: A task tracker used to formalize and report model performance metrics. Now GraphStorm only supports sagemaker_task_tracker which prints evaluation metrics in a formatted way so that a user can capture those metrics through SageMaker. See Monitor and Analyze Training Jobs Using Amazon CloudWatch Metrics  for more details.</dt><dd><ul>
<li><p>Yaml: <code class="docutils literal notranslate"><span class="pre">task_tracker:</span> <span class="pre">sagemaker_task_tracker</span></code></p></li>
<li><p>Argument: <code class="docutils literal notranslate"><span class="pre">--task_tracker</span> <span class="pre">sagemaker_task_tracker</span></code></p></li>
<li><p>Default value: <code class="docutils literal notranslate"><span class="pre">sagemaker_task_tracker</span></code></p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>log_report_frequency</strong>: The frequency of reporting model performance metrics through task_tracker. The frequency is defined by using number of iterations, i.e., every N iterations the evaluation metrics will be reported. (Please note the evaluation metrics should be generated at the reporting iteration. See “eval_frequency” for how evaluation frequency is controlled.)</dt><dd><ul>
<li><p>Yaml: <code class="docutils literal notranslate"><span class="pre">log_report_frequency:</span> <span class="pre">1000</span></code></p></li>
<li><p>Argument: <code class="docutils literal notranslate"><span class="pre">--log-report-frequency</span> <span class="pre">1000</span></code></p></li>
<li><p>Default value: <code class="docutils literal notranslate"><span class="pre">1000</span></code></p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>restore_model_path</strong>: A path where GraphStorm model parameters were saved. For training, if restore_model_path is set, GraphStom will retrieve the model parameters from restore_model_path instead of initializing the parameters. For inference, restore_model_path must be provided.</dt><dd><ul>
<li><p>Yaml: <code class="docutils literal notranslate"><span class="pre">restore_model_path:</span> <span class="pre">/model/checkpoint/</span></code></p></li>
<li><p>Argument: <code class="docutils literal notranslate"><span class="pre">--restore-model-path</span> <span class="pre">/model/checkpoint/</span></code></p></li>
<li><p>Default value: This parameter must be provided if users want to restore a saved model.</p></li>
</ul>
</dd>
</dl>
</li>
<li><p><strong>restore_model_layers</strong>: Specify which GraphStorm neural network layers to load. This argument is useful when a user wants to pre-train a GraphStorm model using link prediction and fine-tune the same model on a node or edge classification/regression task.</p></li>
</ul>
<dl class="simple">
<dt>Currently, three neural network layers are supported, i.e., <code class="docutils literal notranslate"><span class="pre">embed</span></code> (input layer), <code class="docutils literal notranslate"><span class="pre">gnn</span></code> and <code class="docutils literal notranslate"><span class="pre">decoder</span></code>. A user can select one or more layers to load.</dt><dd><ul class="simple">
<li><p>Yaml: <code class="docutils literal notranslate"><span class="pre">restore_model_path:</span> <span class="pre">embed</span></code></p></li>
<li><p>Argument: <code class="docutils literal notranslate"><span class="pre">--restore-model-layers</span> <span class="pre">embed,gnn</span></code></p></li>
<li><p>Default value: Load all neural network layers</p></li>
</ul>
</dd>
</dl>
<ul class="simple">
<li><dl class="simple">
<dt><strong>restore_optimizer_path</strong>: A path storing optimizer status corresponding to GraphML model parameters. This is used when a user wants to fine-tune a model from a pre-trained one.</dt><dd><ul>
<li><p>Yaml: <code class="docutils literal notranslate"><span class="pre">restore_optimizer_path:</span> <span class="pre">/model/checkpoint/optimizer</span></code></p></li>
<li><p>Argument: <code class="docutils literal notranslate"><span class="pre">--restore-optimizer-path</span> <span class="pre">/model/checkpoint/optimizer</span></code></p></li>
<li><p>Default value: This parameter must be provided if users want to restore a saved optimizer.</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</section>
<section id="model-training-hyper-parameters-configurations">
<h2>Model Training Hyper-parameters Configurations<a class="headerlink" href="#model-training-hyper-parameters-configurations" title="Permalink to this heading">#</a></h2>
<p>GraphStorm provides a set of parameters to control training hyper-parameters.</p>
<ul class="simple">
<li><dl class="simple">
<dt><strong>fanout</strong>: The fanout of each GNN layers. The fanouts must be integers larger than 0. The number of fanouts must equal to num_layers. It accepts two formats: a) <cite>“20,10”</cite>, it defines number of neighbors to sample per edge type for each GNN layer with the ith element being the fanout for the ith GNN layer. In the example, the fanout of the 0th GNN layer is 20 and the fanout of the 1st GNN layer is 10. b) <cite>&quot;etype2:20&#64;etype3:20&#64;etype1:10,etype2:10&#64;etype3:4&#64;etype1:2&quot;</cite>. It defines the numbers of neighbors to sample for different edge types for each GNN layers with the i-th element being the fanout for the i-th GNN layer. In the example, the fanouts of etype2, etype3 and etype1 of 0th GNN layer are 20, 20 and 10 respectively and the fanouts of etype2, etype3 and etype1 of 0th GNN layer are 10, 4 and 2 respectively. Each etype (e.g., etype2) should be a canonical etype in format of <cite>&quot;srcntype/relation/dstntype&quot;</cite></dt><dd><ul>
<li><p>Yaml: <code class="docutils literal notranslate"><span class="pre">fanout:</span> <span class="pre">10,10</span></code></p></li>
<li><p>Argument: <code class="docutils literal notranslate"><span class="pre">--fanout</span> <span class="pre">10,10</span></code></p></li>
<li><p>Default value: This parameter must be provided by user. But if set the <code class="docutils literal notranslate"><span class="pre">--num_layers</span></code> to be 0, which means there is no GNN layer, no need to specify this configuration.</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>dropout</strong>: Dropout probability. Dropout must be a float value in [0,1). Dropout is applied to every GNN layer(s).</dt><dd><ul>
<li><p>Yaml: <code class="docutils literal notranslate"><span class="pre">dropout:</span> <span class="pre">0.5</span></code></p></li>
<li><p>Argument: <code class="docutils literal notranslate"><span class="pre">--dropout</span> <span class="pre">0.5</span></code></p></li>
<li><p>Default value: <code class="docutils literal notranslate"><span class="pre">0.0</span></code></p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>lr</strong>: (<strong>Required</strong>) Learning rate. Learning rate for dense parameters of input encoder, model encoder and decoder.</dt><dd><ul>
<li><p>Yaml: <code class="docutils literal notranslate"><span class="pre">lr:</span> <span class="pre">0.5</span></code></p></li>
<li><p>Argument: <code class="docutils literal notranslate"><span class="pre">--lr</span> <span class="pre">0.5</span></code></p></li>
<li><p>Default value: This parameter must be provided by user.</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>num_epochs</strong>: Number of training epochs. Must be integer.</dt><dd><ul>
<li><p>Yaml: <code class="docutils literal notranslate"><span class="pre">num_epochs:</span> <span class="pre">5</span></code></p></li>
<li><p>Argument: <code class="docutils literal notranslate"><span class="pre">--num-epochs</span> <span class="pre">5</span></code></p></li>
<li><p>Default value: <code class="docutils literal notranslate"><span class="pre">0</span></code>. By default only do testing/inference.</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>batch_size</strong>: (<strong>Required</strong>) Mini-batch size. It defines the batch size of each trainer. The global batch size equals to the number of trainers multiply the batch_size. For example, suppose we have 2 machines each with 8 GPUs and set batch_size to 128. The global batch size will be 2 * 8 * 128 = 2048.</dt><dd><ul>
<li><p>Yaml: <code class="docutils literal notranslate"><span class="pre">batch_size:</span> <span class="pre">128</span></code></p></li>
<li><p>Argument: <code class="docutils literal notranslate"><span class="pre">--batch_size</span> <span class="pre">128</span></code></p></li>
<li><p>Default value: This parameter must be provided by user.</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>sparse_optimizer_lr</strong>: Learning rate of sparse optimizer. Learning rate for the optimizer corresponding to learnable sparse embeddings.</dt><dd><ul>
<li><p>Yaml: <code class="docutils literal notranslate"><span class="pre">sparse_optimizer_lr:</span> <span class="pre">0.5</span></code></p></li>
<li><p>Argument: <code class="docutils literal notranslate"><span class="pre">--sparse-optimizer-lr</span> <span class="pre">0.5</span></code></p></li>
<li><p>Default value: Same as lr.</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>use_node_embeddings</strong>: Set true to use extra learnable node embedding for each node.</dt><dd><ul>
<li><p>Yaml: <code class="docutils literal notranslate"><span class="pre">use_node_embeddings:</span> <span class="pre">true</span></code></p></li>
<li><p>Argument: <code class="docutils literal notranslate"><span class="pre">--use-node-embeddings</span> <span class="pre">true</span></code></p></li>
<li><p>Default value: <code class="docutils literal notranslate"><span class="pre">false</span></code></p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>wd_l2norm</strong>: Weight decay used by torch.optim.Adam.</dt><dd><ul>
<li><p>Yaml: <code class="docutils literal notranslate"><span class="pre">wd_l2norm:</span> <span class="pre">0.1</span></code></p></li>
<li><p>Argument: <code class="docutils literal notranslate"><span class="pre">--wd-l2norm</span> <span class="pre">0.1</span></code></p></li>
<li><p>Default value: <code class="docutils literal notranslate"><span class="pre">0</span></code></p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>alpha_l2norm</strong>: Coefficiency of the l2 norm of dense parameters. GraphStorm adds a regularization loss, i.e., l2 norm of dense parameters, to the final loss. It uses alpha_l2norm to re-scale the regularization loss. Specifically, loss = loss +  alpha_l2norm * regularization_loss.</dt><dd><ul>
<li><p>Yaml: <code class="docutils literal notranslate"><span class="pre">alpha_l2norm:</span> <span class="pre">0.00001</span></code></p></li>
<li><p>Argument: <code class="docutils literal notranslate"><span class="pre">--alpha-l2norm</span> <span class="pre">0.00001</span></code></p></li>
<li><p>Default value: <code class="docutils literal notranslate"><span class="pre">0.0</span></code></p></li>
</ul>
</dd>
</dl>
</li>
</ul>
<section id="early-stop-configurations">
<h3>Early stop configurations<a class="headerlink" href="#early-stop-configurations" title="Permalink to this heading">#</a></h3>
<p>GraphStorm provides a set of parameters to control early stop of training. By default, GraphStorm finishes training after num_epochs. One can use early stop to exit model training earlier.</p>
<p>Every time evaluation is triggered, GraphStorm checks early stop criteria. For the rounds within early_stop_burnin_rounds evaluation calls, GraphStorm will not use early stop. After early_stop_burnin_rounds, GraphStorm decides if stop early based on the <strong>early_stop_strategy</strong>. There are two strategies: 1) <strong>consecutive_increase</strong>, early stop is triggered if the current validation score is lower than the average of the last <strong>early_stop_rounds</strong> validation scores and 2) <strong>average_increase</strong>, early stop is triggered if for the last <strong>early_stop_rounds</strong> consecutive steps, the validation scores are <cite>decreasing</cite>.</p>
<ul class="simple">
<li><dl class="simple">
<dt><strong>early_stop_burnin_rounds</strong>: Burning period calls to start considering early stop.</dt><dd><ul>
<li><p>Yaml: <code class="docutils literal notranslate"><span class="pre">early_stop_burnin_rounds:</span> <span class="pre">100</span></code></p></li>
<li><p>Argument: <code class="docutils literal notranslate"><span class="pre">--early-stop-burnin-rounds</span> <span class="pre">100</span></code></p></li>
<li><p>Default value: <code class="docutils literal notranslate"><span class="pre">0.0</span></code></p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>early_stop_rounds</strong>: The number of rounds for validation scores used to decide if early stop.</dt><dd><ul>
<li><p>Yaml: <code class="docutils literal notranslate"><span class="pre">early_stop_rounds:</span> <span class="pre">5</span></code></p></li>
<li><p>Argument: <code class="docutils literal notranslate"><span class="pre">--early-stop-rounds</span> <span class="pre">5</span></code></p></li>
<li><p>Default value: <code class="docutils literal notranslate"><span class="pre">3.</span></code></p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>early_stop_strategy</strong>: GraphStorm supports two strategies: 1) consecutive_increase and 2) average_increase.</dt><dd><ul>
<li><p>Yaml: <code class="docutils literal notranslate"><span class="pre">early_stop_strategy:</span> <span class="pre">consecutive_increase</span></code></p></li>
<li><p>Argument: <code class="docutils literal notranslate"><span class="pre">--early-stop-strategy</span> <span class="pre">average_increase</span></code></p></li>
<li><p>Default value: <code class="docutils literal notranslate"><span class="pre">average_increase</span></code></p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>use_early_stop</strong>: Set true to enable early stop.</dt><dd><ul>
<li><p>Yaml: <code class="docutils literal notranslate"><span class="pre">use_early_stop:</span> <span class="pre">true</span></code></p></li>
<li><p>Argument: <code class="docutils literal notranslate"><span class="pre">--use-early-stop</span> <span class="pre">true</span></code></p></li>
<li><p>Default value: <code class="docutils literal notranslate"><span class="pre">false</span></code></p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</section>
</section>
<section id="model-evaluation-configurations">
<h2>Model Evaluation Configurations<a class="headerlink" href="#model-evaluation-configurations" title="Permalink to this heading">#</a></h2>
<p>GraphStorm provides a set of parameters to control model evaluation.</p>
<ul class="simple">
<li><dl class="simple">
<dt><strong>eval_batch_size</strong>: Mini-batch size for computing GNN embeddings in evaluation. You can set eval_batch_size larger than batch_size to speedup GNN embedding computation. To be noted, a larger eval_batch_size will consume more GPU memory.</dt><dd><ul>
<li><p>Yaml: <code class="docutils literal notranslate"><span class="pre">eval_batch_size:</span> <span class="pre">1024</span></code></p></li>
<li><p>Argument: <code class="docutils literal notranslate"><span class="pre">--eval-batch-size</span> <span class="pre">1024</span></code></p></li>
<li><p>Default value: 10000.</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>eval_fanout</strong>: (<strong>Required</strong>) The fanout of each GNN layers used in evaluation and inference. It follows the same format as fanout.</dt><dd><ul>
<li><p>Yaml: <code class="docutils literal notranslate"><span class="pre">eval_fanout:</span> <span class="pre">&quot;10,10&quot;</span></code></p></li>
<li><p>Argument: <code class="docutils literal notranslate"><span class="pre">--eval-fanout</span> <span class="pre">10,10</span></code></p></li>
<li><p>Default value: This parameter must be provided by user. But if set the <code class="docutils literal notranslate"><span class="pre">--num_layers</span></code> to be 0, which means there is no GNN layer, no need to specify this configuration.</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>use_mini_batch_infer</strong>: Set true to do mini-batch inference during evaluation and inference. Set false to do full-graph inference during evaluation and inference. For node classification/regression and edge classification/regression tasks, if the evaluation set or testing set is small, mini-batch inference can be more efficient as it does not waste resources to compute node embeddings for nodes not used during inference. However, if the test set is large or the task is link prediction, full graph inference (set use_mini_batch_infer to false) is preferred, as it avoids recomputing node embeddings during inference.</dt><dd><ul>
<li><p>Yaml: <code class="docutils literal notranslate"><span class="pre">use_mini_batch_infer:</span> <span class="pre">false</span></code></p></li>
<li><p>Argument: <code class="docutils literal notranslate"><span class="pre">--use-mini-batch-infer</span> <span class="pre">false</span></code></p></li>
<li><p>Default value: <code class="docutils literal notranslate"><span class="pre">true</span></code></p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>eval_frequency</strong>: The frequency of doing evaluation. GraphStorm trainers do evaluation at the end of each epoch. However, for large-scale graphs, training one epoch may take hundreds of thousands of iterations. One may want to do evaluations in the middle of an epoch. When eval_frequency is set, every <strong>eval_frequency</strong> iterations, the trainer will do evaluation once. The evaluation results can be printed and reported. See <strong>log_report_frequency</strong> for more details.</dt><dd><ul>
<li><p>Yaml: <code class="docutils literal notranslate"><span class="pre">eval_frequency:</span> <span class="pre">10000</span></code></p></li>
<li><p>Argument: <code class="docutils literal notranslate"><span class="pre">--eval-frequency</span> <span class="pre">10000</span></code></p></li>
<li><p>Default value: <code class="docutils literal notranslate"><span class="pre">sys.maxsize</span></code>. The system will not do evaluation.</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>no_validation</strong>: Set true to avoid do model evaluation (validation) during training.</dt><dd><ul>
<li><p>Yaml: <code class="docutils literal notranslate"><span class="pre">no_validation:</span> <span class="pre">true</span></code></p></li>
<li><p>Argument: <code class="docutils literal notranslate"><span class="pre">--no-validation</span> <span class="pre">true</span></code></p></li>
<li><p>Default value: <code class="docutils literal notranslate"><span class="pre">false</span></code></p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</section>
<section id="language-model-specific-configurations">
<h2>Language Model Specific Configurations<a class="headerlink" href="#language-model-specific-configurations" title="Permalink to this heading">#</a></h2>
<p>GraphStorm supports co-training language models with GNN. GraphStorm provides a set of parameters to control language model fine-tuning.</p>
<ul class="simple">
<li><dl class="simple">
<dt><strong>lm_tune_lr</strong>: Learning rate for fine-tuning language model.</dt><dd><ul>
<li><p>Yaml: <code class="docutils literal notranslate"><span class="pre">lm_tune_lr:</span> <span class="pre">0.0001</span></code></p></li>
<li><p>Argument: <code class="docutils literal notranslate"><span class="pre">--lm-tune-lr</span> <span class="pre">0.0001</span></code></p></li>
<li><p>Default value: same as <strong>lr</strong></p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>lm_train_nodes</strong>: Number of nodes used in LM model fine-tuning for each different LM model.</dt><dd><ul>
<li><p>Yaml: <code class="docutils literal notranslate"><span class="pre">lm_train_nodes:</span> <span class="pre">10</span></code></p></li>
<li><p>Argument: <code class="docutils literal notranslate"><span class="pre">--lm-train-nodes</span> <span class="pre">10</span></code></p></li>
<li><p>Default value: <code class="docutils literal notranslate"><span class="pre">0</span></code></p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>lm_infer_batch_size</strong>: Batch size used in LM model inference.</dt><dd><ul>
<li><p>Yaml: <code class="docutils literal notranslate"><span class="pre">lm_infer_batch_size:</span> <span class="pre">10</span></code></p></li>
<li><p>Argument: <code class="docutils literal notranslate"><span class="pre">--lm-infer-batch-size</span> <span class="pre">10</span></code></p></li>
<li><p>Default value: <code class="docutils literal notranslate"><span class="pre">32</span></code></p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>freeze_lm_encoder_epochs</strong>: Before fine-tuning LM model, how many epochs we will take to warmup a GNN model.</dt><dd><ul>
<li><p>Yaml: <code class="docutils literal notranslate"><span class="pre">freeze_lm_encoder_epochs:</span> <span class="pre">1</span></code></p></li>
<li><p>Argument: <code class="docutils literal notranslate"><span class="pre">--freeze-lm-encoder-epochs</span> <span class="pre">1</span></code></p></li>
<li><p>Default value: <code class="docutils literal notranslate"><span class="pre">0</span></code></p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</section>
<section id="task-specific-configurations">
<h2>Task Specific Configurations<a class="headerlink" href="#task-specific-configurations" title="Permalink to this heading">#</a></h2>
<p>GraphStorm supports node classification, node regression, edge classification, edge regression and link prediction tasks. It provides rich task related configurations.</p>
<section id="general-configurations">
<h3>General Configurations<a class="headerlink" href="#general-configurations" title="Permalink to this heading">#</a></h3>
<ul>
<li><dl class="simple">
<dt><strong>task_type</strong>: (<strong>Required</strong>) Supported task type includes node_classification, node_regression, edge_classification, edge_regression, and link_prediction.</dt><dd><ul class="simple">
<li><p>Yaml: <code class="docutils literal notranslate"><span class="pre">task_type:</span> <span class="pre">node_classification</span></code></p></li>
<li><p>Argument: <code class="docutils literal notranslate"><span class="pre">--task-type</span> <span class="pre">node_classification</span></code></p></li>
<li><p>Default value: This parameter must be provided by user.</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl>
<dt><strong>eval_metric</strong>: Evaluation metric used during evaluation. The input can be a string specifying the evaluation metric to report or a list of strings specifying a list of evaluation metrics to report. The first evaluation metric is treated as the major metric and is used to choose the best trained model. The supported evaluation metrics of classification tasks include <code class="docutils literal notranslate"><span class="pre">accuracy</span></code>, <code class="docutils literal notranslate"><span class="pre">precision_recall</span></code>, <code class="docutils literal notranslate"><span class="pre">roc_auc</span></code>, <code class="docutils literal notranslate"><span class="pre">f1_score</span></code>, <code class="docutils literal notranslate"><span class="pre">per_class_f1_score</span></code>. The supported evaluation metrics of regression tasks include <code class="docutils literal notranslate"><span class="pre">rmse</span></code> and <code class="docutils literal notranslate"><span class="pre">mse</span></code>. The supported evaluation metrics of link prediction tasks include <code class="docutils literal notranslate"><span class="pre">mrr</span></code>.</dt><dd><ul>
<li><dl>
<dt>Yaml: <code class="docutils literal notranslate"><span class="pre">eval_metric:</span></code></dt><dd><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">-</span> <span class="pre">accuracy</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">-</span> <span class="pre">precision_recall</span></code></div>
</div>
</dd>
</dl>
</li>
<li><p>Argument: <code class="docutils literal notranslate"><span class="pre">--eval-metric</span> <span class="pre">accuracy</span> <span class="pre">precision_recall</span></code></p></li>
<li><dl class="simple">
<dt>Default value:</dt><dd><ul class="simple">
<li><p>For classification tasks, the default value is <code class="docutils literal notranslate"><span class="pre">accuracy</span></code>.</p></li>
<li><p>For regression tasks, the default value is <code class="docutils literal notranslate"><span class="pre">rmse</span></code>.</p></li>
<li><p>For link prediction tasks, the default value is <code class="docutils literal notranslate"><span class="pre">mrr</span></code>.</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</dd>
</dl>
</li>
</ul>
</section>
<section id="classification-and-regression-task">
<h3>Classification and Regression Task<a class="headerlink" href="#classification-and-regression-task" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><dl class="simple">
<dt><strong>label_field</strong>: (<strong>Required</strong>) The field name of labelled data in the graph data. For node classification tasks, GraphStorm use <code class="docutils literal notranslate"><span class="pre">graph.nodes[target_ntype].data[label_field]</span></code> to access node labels. For edge classification tasks, GraphStorm use <code class="docutils literal notranslate"><span class="pre">graph.edges[target_etype].data[label_field]</span></code> to access edge labels.</dt><dd><ul>
<li><p>Yaml: <code class="docutils literal notranslate"><span class="pre">label_field:</span> <span class="pre">color</span></code></p></li>
<li><p>Argument: <code class="docutils literal notranslate"><span class="pre">--label-field</span> <span class="pre">color</span></code></p></li>
<li><p>Default value: This parameter must be provided by user.</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>num_classes</strong>: (<strong>Required</strong>) The cardinality of labels in a classification task. Used by node classification and edge classification.</dt><dd><ul>
<li><p>Yaml: <code class="docutils literal notranslate"><span class="pre">num_classes:</span> <span class="pre">10</span></code></p></li>
<li><p>Argument: <code class="docutils literal notranslate"><span class="pre">--num-classes</span> <span class="pre">10</span></code></p></li>
<li><p>Default value: This parameter must be provided by user.</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>multilabel</strong>: If set to true, the task is a multi-label classification task. Used by node classification and edge classification.</dt><dd><ul>
<li><p>Yaml: <code class="docutils literal notranslate"><span class="pre">multilabel:</span> <span class="pre">true</span></code></p></li>
<li><p>Argument: <code class="docutils literal notranslate"><span class="pre">--multilabel</span> <span class="pre">true</span></code></p></li>
<li><p>Default value: <code class="docutils literal notranslate"><span class="pre">false</span></code></p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>multilabel_weights</strong>: Used to specify label weight of each class in a multi-label classification task. This is used together with <strong>multilabel</strong>. It is feed into <code class="docutils literal notranslate"><span class="pre">torch.nn.BCEWithLogitsLoss</span></code>. The weights should be in the following format <cite>0.1,0.2,0.3,0.1,0.0</cite>. Each field represents a weight for a class. Suppose there are 3 classes. The multilabel_weights is set to <cite>0.1,0.2,0.3</cite>. Class 0 will have weight of 0.1, class 1 will have weight of 0.2 and class 2 will have weight of 0.3. For more details, see <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.BCEWithLogitsLoss.html">BCEWithLogitsLoss</a>. If not provided, all classes are treated equally.</dt><dd><ul>
<li><p>Yaml: <code class="docutils literal notranslate"><span class="pre">multilabel_weights:</span> <span class="pre">0.1,0.2,0.3</span></code></p></li>
<li><p>Argument: <code class="docutils literal notranslate"><span class="pre">--multilabel-weights</span> <span class="pre">0.1,0.2,0.3</span></code></p></li>
<li><p>Default value: <code class="docutils literal notranslate"><span class="pre">None</span></code></p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>imbalance_class_weights</strong>: Used to specify a manual rescaling weight given to each class in a single-label multi-class classification task. It is used in imbalanced label use cases. It is feed into torch.nn.CrossEntropyLoss. Each field represents a weight for a class. Suppose there are 3 classes. The imbalance_class_weights is set to <cite>0.1,0.2,0.3</cite>. Class 0 will have weight of 0.1, class 1 will have weight of 0.2 and class 2 will have weight of 0.3. If not provided, all classes are treated equally.</dt><dd><ul>
<li><p>Yaml: <code class="docutils literal notranslate"><span class="pre">imbalance_class_weights:</span> <span class="pre">0.1,0.2,0.3</span></code></p></li>
<li><p>Argument: <code class="docutils literal notranslate"><span class="pre">--imbalance-class-weights</span> <span class="pre">0.1,0.2,0.3</span></code></p></li>
<li><p>Default value: <code class="docutils literal notranslate"><span class="pre">None</span></code></p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>save_prediction_path</strong>: Path to save prediction results. This is used in node/edge classification/regression inference.</dt><dd><ul>
<li><p>Yaml: <code class="docutils literal notranslate"><span class="pre">save_prediction_path:</span> <span class="pre">/data/infer-output/predictions/</span></code></p></li>
<li><p>Argument: <code class="docutils literal notranslate"><span class="pre">--save-prediction-path</span> <span class="pre">/data/infer-output/predictions/</span></code></p></li>
<li><p>Default value: If not provided, it will be the same as save_embed_path.</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</section>
<section id="node-classification-regression-specific">
<h3>Node Classification/Regression Specific<a class="headerlink" href="#node-classification-regression-specific" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><dl class="simple">
<dt><strong>target_ntype</strong>: (<strong>Required</strong>) The node type for prediction.</dt><dd><ul>
<li><p>Yaml: <code class="docutils literal notranslate"><span class="pre">target_ntype:</span> <span class="pre">movie</span></code></p></li>
<li><p>Argument: <code class="docutils literal notranslate"><span class="pre">--target-ntype</span> <span class="pre">movie</span></code></p></li>
<li><p>Default value: This parameter must be provided by user.</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</section>
<section id="edge-classification-regression-specific">
<h3>Edge Classification/Regression Specific<a class="headerlink" href="#edge-classification-regression-specific" title="Permalink to this heading">#</a></h3>
<ul>
<li><dl>
<dt><strong>target_etype</strong>: (<strong>Required</strong>) The list of canonical edge types that will be added as a training target in edge classification/regression tasks, for example <code class="docutils literal notranslate"><span class="pre">--train-etype</span> <span class="pre">query,clicks,asin</span></code> or <code class="docutils literal notranslate"><span class="pre">--train-etype</span> <span class="pre">query,clicks,asin</span> <span class="pre">query,search,asin</span></code>. A canonical edge type should be formatted as <cite>src_node_type,relation_type,dst_node_type</cite>. Currently, GraphStorm only supports single task edge classification/regression, i.e., it only accepts one canonical edge type.</dt><dd><ul>
<li><dl>
<dt>Yaml: <code class="docutils literal notranslate"><span class="pre">target_etype:</span></code></dt><dd><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">-</span> <span class="pre">query,clicks,asin</span></code></div>
</div>
</dd>
</dl>
</li>
<li><p>Argument: <code class="docutils literal notranslate"><span class="pre">--target-etype</span> <span class="pre">query,clicks,asin</span></code></p></li>
<li><p>Default value: This parameter must be provided by user.</p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>remove_target_edge_type</strong>: When set to true, GraphStorm removes target_etype in message passing, i.e., any edge with target_etype will not be sampled during training and inference.</dt><dd><ul class="simple">
<li><p>Yaml: <code class="docutils literal notranslate"><span class="pre">remove_target_edge_type:</span> <span class="pre">false</span></code></p></li>
<li><p>Argument: <code class="docutils literal notranslate"><span class="pre">--remove-target-edge-type</span> <span class="pre">false</span></code></p></li>
<li><p>Default value: <code class="docutils literal notranslate"><span class="pre">true</span></code></p></li>
</ul>
</dd>
</dl>
</li>
<li><dl>
<dt><strong>reverse_edge_types_map</strong>: A list of reverse edge type info. Each edge type is in the following format: <cite>head,relation,reverse_relation,tail</cite>. For example: <cite>[“query,adds,rev-adds,asin”, “query,clicks,rev-clicks,asin”]</cite>. For edge classification/regression tasks, if <strong>remove_target_edge_type</strong> is set true and <strong>reverse_edge_type_map</strong> is provided, GraphStorm will remove both <strong>target_etype</strong> and the corresponding reverse edge type(s) in message passing. In certain cases, any edge with <strong>target_etype</strong> or reverse <strong>target_etype</strong> will not be sampled during training and inference. For link prediction tasks, if <strong>exclude_training_targets</strong> is set to <code class="docutils literal notranslate"><span class="pre">true</span></code> and <strong>reverse_edge_type_map</strong> is provided, GraphStorm will remove both target edges with <strong>train_etype</strong> and the corresponding reverse edges with the reverse edge types of <strong>train_etype</strong> in message passing. In contrast to edge classification/regression tasks, for link prediction tasks, GraphStorm only excludes specific edges instead of all edges with <strong>target_etype</strong> or reverse <strong>target_etype</strong> in message passing.</dt><dd><ul>
<li><dl>
<dt>Yaml: <code class="docutils literal notranslate"><span class="pre">reverse_edge_types_map:</span></code></dt><dd><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">-</span> <span class="pre">query,adds,rev-adds,asin</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">-</span> <span class="pre">query,clicks,rev-clicks,asin</span></code></div>
</div>
</dd>
</dl>
</li>
<li><p>Argument: <code class="docutils literal notranslate"><span class="pre">--reverse-edge-types-map</span> <span class="pre">query,adds,rev-adds,asin</span> <span class="pre">query,clicks,rev-clicks,asin</span></code></p></li>
<li><p>Default value: <code class="docutils literal notranslate"><span class="pre">None</span></code></p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>decoder_type</strong>: Type of edge classification or regression decoder. Built-in decoders include <code class="docutils literal notranslate"><span class="pre">DenseBiDecoder</span></code> and <code class="docutils literal notranslate"><span class="pre">MLPDecoder</span></code>. <code class="docutils literal notranslate"><span class="pre">DenseBiDecoder</span></code> implements the bi-linear decoder used in GCMC. <code class="docutils literal notranslate"><span class="pre">MLPEdgeDecoder</span></code> simply applies Multilayer Perceptron layers for prediction.</dt><dd><ul class="simple">
<li><p>Yaml: <code class="docutils literal notranslate"><span class="pre">decoder-type:</span> <span class="pre">DenseBiDecoder</span></code></p></li>
<li><p>Argument: <code class="docutils literal notranslate"><span class="pre">--decoder-type</span> <span class="pre">MLPDecoder</span></code></p></li>
<li><p>Default value: <code class="docutils literal notranslate"><span class="pre">DenseBiDecoder</span></code></p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>num_decoder_basis</strong>: The number of basis for DenseBiDecoder in edge prediction task.</dt><dd><ul class="simple">
<li><p>Yaml: <code class="docutils literal notranslate"><span class="pre">num_decoder_basis:</span> <span class="pre">2</span></code></p></li>
<li><p>Argument: <code class="docutils literal notranslate"><span class="pre">--num-decoder-basis</span> <span class="pre">2</span></code></p></li>
<li><p>Default value: <code class="docutils literal notranslate"><span class="pre">2</span></code></p></li>
</ul>
</dd>
</dl>
</li>
<li><dl>
<dt><strong>decoder_edge_feat</strong>: A list of edge features that can be used by a decoder to enhance its performance.</dt><dd><ul>
<li><dl>
<dt>Yaml: <code class="docutils literal notranslate"><span class="pre">decoder_edge_feat:</span></code></dt><dd><blockquote>
<div><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">-</span> <span class="pre">&quot;fname&quot;</span></code></div>
</div>
</div></blockquote>
<dl class="simple">
<dt>Or</dt><dd><p><code class="docutils literal notranslate"><span class="pre">decoder_edge_feat:</span></code>
| <code class="docutils literal notranslate"><span class="pre">-</span> <span class="pre">query,adds,asin:count,price</span></code></p>
</dd>
</dl>
</dd>
</dl>
</li>
<li><p>Argument: <code class="docutils literal notranslate"><span class="pre">--decoder-edge-feat</span> <span class="pre">fanme</span></code> or <code class="docutils literal notranslate"><span class="pre">--decoder-edge-feat</span> <span class="pre">query,adds,asin:count,price</span></code></p></li>
<li><p>Default value: <code class="docutils literal notranslate"><span class="pre">None</span></code></p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</section>
<section id="link-prediction-task">
<h3>Link Prediction Task<a class="headerlink" href="#link-prediction-task" title="Permalink to this heading">#</a></h3>
<ul>
<li><dl>
<dt><strong>train_etype</strong>: The list of canonical edge type that will be added as training target with the target edge type(s). If not provided, all edge types will be used as training target. A canonical edge type should be formatted as <cite>src_node_type,relation_type,dst_node_type</cite>.</dt><dd><ul>
<li><dl>
<dt>Yaml: <code class="docutils literal notranslate"><span class="pre">train_etype:</span></code></dt><dd><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">-</span> <span class="pre">query,clicks,asin</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">-</span> <span class="pre">query,adds,asin</span></code></div>
</div>
</dd>
</dl>
</li>
<li><p>Argument: <code class="docutils literal notranslate"><span class="pre">--train-etype</span> <span class="pre">query,clicks,asin</span> <span class="pre">query,adds,asin</span></code></p></li>
<li><p>Default value: <code class="docutils literal notranslate"><span class="pre">None</span></code></p></li>
</ul>
</dd>
</dl>
</li>
<li><dl>
<dt><strong>eval_etype</strong>: The list of canonical edge type that will be added as evaluation target with the target edge type(s). If not provided, all edge types will be used as evaluation target. In some link prediction use cases, users want to train a model using all edges of a graph but only do link prediction on specific edge type(s) for downstream applications. In certain cases, they only care about the model performance on specific edge types.</dt><dd><ul>
<li><dl>
<dt>Yaml: <code class="docutils literal notranslate"><span class="pre">eval_etype:</span></code></dt><dd><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">-</span> <span class="pre">query,clicks,asin</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">-</span> <span class="pre">query,adds,asin</span></code></div>
</div>
</dd>
</dl>
</li>
<li><p>Argument: <code class="docutils literal notranslate"><span class="pre">--eval-etype</span> <span class="pre">query,clicks,asin</span> <span class="pre">query,adds,asin</span></code></p></li>
<li><p>Default value: <code class="docutils literal notranslate"><span class="pre">None</span></code></p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>exclude_training_targets</strong>: If it is set to <code class="docutils literal notranslate"><span class="pre">true</span></code>, GraphStorm removes the training targets from the GNN computation graph. If true, <strong>reverse_edge_types_map</strong> <strong>MUST</strong> be provided.</dt><dd><ul class="simple">
<li><p>Yaml: <code class="docutils literal notranslate"><span class="pre">exclude_training_targets:</span> <span class="pre">false</span></code></p></li>
<li><p>Argument: <code class="docutils literal notranslate"><span class="pre">--exclude-training-targets</span> <span class="pre">false</span></code></p></li>
<li><p>Default value: <code class="docutils literal notranslate"><span class="pre">true</span></code></p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>train_negative_sampler</strong>: The negative sampler used for link prediction training. Built-in samplers include <code class="docutils literal notranslate"><span class="pre">uniform</span></code>, <code class="docutils literal notranslate"><span class="pre">joint</span></code>, <code class="docutils literal notranslate"><span class="pre">localuniform</span></code>, <code class="docutils literal notranslate"><span class="pre">all_etype_uniform</span></code> and <code class="docutils literal notranslate"><span class="pre">all_etype_joint</span></code>.</dt><dd><ul class="simple">
<li><p>Yaml: <code class="docutils literal notranslate"><span class="pre">train_negative_sampler:</span> <span class="pre">uniform</span></code></p></li>
<li><p>Argument: <code class="docutils literal notranslate"><span class="pre">--train-negative-sampler</span> <span class="pre">joint</span></code></p></li>
<li><p>Default value: <code class="docutils literal notranslate"><span class="pre">uniform</span></code></p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>eval_negative_sampler</strong>: The negative sampler used for link prediction testing and evaluation. Built-in samplers include <code class="docutils literal notranslate"><span class="pre">uniform</span></code>, <code class="docutils literal notranslate"><span class="pre">joint</span></code>, <code class="docutils literal notranslate"><span class="pre">localuniform</span></code>, <code class="docutils literal notranslate"><span class="pre">all_etype_uniform</span></code> and <code class="docutils literal notranslate"><span class="pre">all_etype_joint</span></code>.</dt><dd><ul class="simple">
<li><p>Yaml: <code class="docutils literal notranslate"><span class="pre">eval_negative_sampler:</span> <span class="pre">uniform</span></code></p></li>
<li><p>Argument: <code class="docutils literal notranslate"><span class="pre">--eval-negative-sampler</span> <span class="pre">joint</span></code></p></li>
<li><p>Default value: <code class="docutils literal notranslate"><span class="pre">joint</span></code></p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>num_negative_edges</strong>: Number of negative edges sampled for each positive edge during training.</dt><dd><ul class="simple">
<li><p>Yaml: <code class="docutils literal notranslate"><span class="pre">num_negative_edges:</span> <span class="pre">32</span></code></p></li>
<li><p>Argument: <code class="docutils literal notranslate"><span class="pre">--num-negative-edges</span> <span class="pre">32</span></code></p></li>
<li><p>Default value: <code class="docutils literal notranslate"><span class="pre">16</span></code></p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>num_negative_edges_eval</strong>: Number of negative edges sampled for each positive edge in the validation and test set.</dt><dd><ul class="simple">
<li><p>Yaml: <code class="docutils literal notranslate"><span class="pre">num_negative_edges_eval:</span> <span class="pre">1000</span></code></p></li>
<li><p>Argument: <code class="docutils literal notranslate"><span class="pre">--num-negative-edges-eval</span> <span class="pre">1000</span></code></p></li>
<li><p>Default value: <code class="docutils literal notranslate"><span class="pre">1000</span></code></p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>lp_decoder_type</strong>: Set the decoder type for loss function in Link Prediction tasks. Currently GraphStorm support  <code class="docutils literal notranslate"><span class="pre">dot_product</span></code> and <code class="docutils literal notranslate"><span class="pre">DistMult</span></code>.</dt><dd><ul class="simple">
<li><p>Yaml: <code class="docutils literal notranslate"><span class="pre">lp_decoder_type:</span> <span class="pre">dot_product</span></code></p></li>
<li><p>Argument: <code class="docutils literal notranslate"><span class="pre">--lp-decoder-type</span> <span class="pre">dot_product</span></code></p></li>
<li><p>Default value: <code class="docutils literal notranslate"><span class="pre">dot_product</span></code></p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>gamma</strong>: Gamma for <code class="docutils literal notranslate"><span class="pre">DistMult</span></code>. The margin value in the score function.</dt><dd><ul class="simple">
<li><p>Yaml: <code class="docutils literal notranslate"><span class="pre">gamma:</span> <span class="pre">10.0</span></code></p></li>
<li><p>Argument: <code class="docutils literal notranslate"><span class="pre">--gamma</span> <span class="pre">10.0</span></code></p></li>
<li><p>Default value: <code class="docutils literal notranslate"><span class="pre">12.0</span></code></p></li>
</ul>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt><strong>lp_loss_func</strong>: Link prediction loss function. Builtin loss functions include <code class="docutils literal notranslate"><span class="pre">cross_entropy</span></code> and <code class="docutils literal notranslate"><span class="pre">logsigmoid</span></code>.</dt><dd><ul class="simple">
<li><p>Yaml: <code class="docutils literal notranslate"><span class="pre">lp_loss_func:</span> <span class="pre">cross_entropy</span></code></p></li>
<li><p>Argument: <code class="docutils literal notranslate"><span class="pre">--lp-loss-func</span> <span class="pre">logsigmoid</span></code></p></li>
<li><p>Default value: <code class="docutils literal notranslate"><span class="pre">cross_entropy</span></code></p></li>
</ul>
</dd>
</dl>
</li>
<li><dl>
<dt><strong>lp_edge_weight_for_loss</strong>: Edge feature field name for edge weight. The edge weight is used to rescale the positive edge loss for link prediction tasks.</dt><dd><ul>
<li><dl>
<dt>Yaml: <code class="docutils literal notranslate"><span class="pre">lp_edge_weight_for_loss:</span></code></dt><dd><blockquote>
<div><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">-</span> <span class="pre">&quot;weight&quot;</span></code></div>
</div>
</div></blockquote>
<dl>
<dt>Or</dt><dd><dl>
<dt><code class="docutils literal notranslate"><span class="pre">lp_edge_weight_for_loss:</span></code></dt><dd><div class="line-block">
<div class="line"><code class="docutils literal notranslate"><span class="pre">-</span> <span class="pre">&quot;ntype0,rel0,ntype1:weight0&quot;</span></code></div>
<div class="line"><code class="docutils literal notranslate"><span class="pre">-</span> <span class="pre">&quot;ntype0,rel1,ntype1:weight1&quot;</span></code></div>
</div>
</dd>
</dl>
</dd>
</dl>
</dd>
</dl>
</li>
<li><p>Argument: <code class="docutils literal notranslate"><span class="pre">--lp-edge-weight-for-loss</span> <span class="pre">ntype0,rel0,ntype1:weight0</span> <span class="pre">ntype0,rel1,ntype1:weight1</span></code></p></li>
<li><p>Default value: None</p></li>
</ul>
</dd>
</dl>
</li>
</ul>
</section>
</section>
</section>

        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          <a class="next-page" href="../scale/distributed.html">
              <div class="page-info">
                <div class="context">
                  <span>Next</span>
                </div>
                <div class="title">Use GraphStorm in a Distributed Cluster</div>
              </div>
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
            </a>
          <a class="prev-page" href="configuration-partition.html">
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
              <div class="page-info">
                <div class="context">
                  <span>Previous</span>
                </div>
                
                <div class="title">Graph Partition</div>
                
              </div>
            </a>
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; 2023, AGML team
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer">
      
      
      <div class="toc-sticky toc-scroll">
        <div class="toc-title-container">
          <span class="toc-title">
            On this page
          </span>
        </div>
        <div class="toc-tree-container">
          <div class="toc-tree">
            <ul>
<li><a class="reference internal" href="#">Training and Inference</a><ul>
<li><a class="reference internal" href="#launch-arguments">Launch Arguments</a></li>
<li><a class="reference internal" href="#environment-configurations">Environment Configurations</a></li>
<li><a class="reference internal" href="#model-configurations">Model Configurations</a><ul>
<li><a class="reference internal" href="#built-in-model-specific-configurations">Built-in Model Specific Configurations</a><ul>
<li><a class="reference internal" href="#rgcn">RGCN</a></li>
<li><a class="reference internal" href="#rgat">RGAT</a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#model-save-restore-configurations">Model Save/Restore Configurations</a></li>
<li><a class="reference internal" href="#model-training-hyper-parameters-configurations">Model Training Hyper-parameters Configurations</a><ul>
<li><a class="reference internal" href="#early-stop-configurations">Early stop configurations</a></li>
</ul>
</li>
<li><a class="reference internal" href="#model-evaluation-configurations">Model Evaluation Configurations</a></li>
<li><a class="reference internal" href="#language-model-specific-configurations">Language Model Specific Configurations</a></li>
<li><a class="reference internal" href="#task-specific-configurations">Task Specific Configurations</a><ul>
<li><a class="reference internal" href="#general-configurations">General Configurations</a></li>
<li><a class="reference internal" href="#classification-and-regression-task">Classification and Regression Task</a></li>
<li><a class="reference internal" href="#node-classification-regression-specific">Node Classification/Regression Specific</a></li>
<li><a class="reference internal" href="#edge-classification-regression-specific">Edge Classification/Regression Specific</a></li>
<li><a class="reference internal" href="#link-prediction-task">Link Prediction Task</a></li>
</ul>
</li>
</ul>
</li>
</ul>

          </div>
        </div>
      </div>
      
      
    </aside>
  </div>
</div><script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/sphinx_highlight.js"></script>
    <script src="../_static/scripts/furo.js"></script>
    </body>
</html>