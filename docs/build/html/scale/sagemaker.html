<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Use GraphStorm on SageMaker &mdash; GraphStorm 0.2 documentation</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../_static/jquery.js"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/sphinx_highlight.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Use Your Own Models" href="../advanced/own-models.html" />
    <link rel="prev" title="Use GraphStorm in a Distributed Cluster" href="distributed.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            GraphStorm
          </a>
              <div class="version">
                0.2
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Get Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../install/env-setup.html">Environment Setup</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/quick-start.html">Standalone Mode Quick Start Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/own-data.html">Use Your Own Data Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../configuration/index.html">GraphStorm Configurations</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Scale to Giant Graphs</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="distributed.html">Use GraphStorm in a Distributed Cluster</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Use GraphStorm on SageMaker</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#prerequisites">Prerequisites</a></li>
<li class="toctree-l2"><a class="reference internal" href="#setup-graphstorm-sagemaker-docker-image">Setup GraphStorm SageMaker Docker Image</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#step-1-build-a-sagemaker-compatible-docker-image">Step 1: Build a SageMaker-compatible Docker image</a></li>
<li class="toctree-l3"><a class="reference internal" href="#step-2-upload-docker-images-to-amazon-ecr-repository">Step 2: Upload Docker Images to Amazon ECR Repository</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#run-graphstorm-on-sagemaker">Run GraphStorm on SageMaker</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#run-graphstorm-with-amazon-sagemaker-service">Run GraphStorm with Amazon SageMaker service</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#prepare-graph-data">Prepare graph data</a></li>
<li class="toctree-l4"><a class="reference internal" href="#launch-training">Launch training</a></li>
<li class="toctree-l4"><a class="reference internal" href="#launch-inference">Launch inference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#run-graphstorm-sagemaker-with-docker-compose">Run GraphStorm SageMaker with Docker Compose</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#get-started">Get Started</a></li>
<li class="toctree-l4"><a class="reference internal" href="#generate-a-docker-compose-file">Generate a Docker Compose file</a></li>
<li class="toctree-l4"><a class="reference internal" href="#run-graphstorm-on-docker-compose-for-training">Run GraphStorm on Docker Compose for Training</a></li>
<li class="toctree-l4"><a class="reference internal" href="#run-graphstorm-on-docker-compose-for-inference">Run GraphStorm on Docker Compose for Inference</a></li>
<li class="toctree-l4"><a class="reference internal" href="#clean-up">Clean Up</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Advanced Topics</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../advanced/own-models.html">Use Your Own Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/language-models.html">Use Text as Node Features</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/advanced-usages.html">GraphStorm Advanced Usages</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../api/graphstorm.html">graphstorm</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/graphstorm.dataloading.html">graphstorm.dataloading</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/graphstorm.model.html">graphstorm.model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/graphstorm.trainer.html">graphstorm.trainer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/graphstorm.inferer.html">graphstorm.inferer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/graphstorm.evaluator.html">graphstorm.evaluator</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/graphstorm.customized.html">customized model APIs</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">GraphStorm</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Use GraphStorm on SageMaker</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/scale/sagemaker.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="use-graphstorm-on-sagemaker">
<span id="distributed-sagemaker"></span><h1>Use GraphStorm on SageMaker<a class="headerlink" href="#use-graphstorm-on-sagemaker" title="Permalink to this heading"></a></h1>
<p>GraphStorm can run on Amazon Sagemaker to leverage SageMaker’s ML DevOps capabilities.</p>
<section id="prerequisites">
<h2>Prerequisites<a class="headerlink" href="#prerequisites" title="Permalink to this heading"></a></h2>
<p>In order to use GraphStorm on Amazon SageMaker, users need to have AWS access to the following AWS services.</p>
<ul class="simple">
<li><p><strong>SageMaker service</strong>. Please refer to <a class="reference external" href="https://aws.amazon.com/pm/sagemaker/">Amazon SageMaker service</a> for how to get access to Amazon SageMaker.</p></li>
<li><p><strong>Amazon ECR</strong>. Please refer to <a class="reference external" href="https://aws.amazon.com/ecr/">Amazon Elastic Container Registry service</a> for how to get access to Amazon ECR.</p></li>
<li><p><strong>S3 service</strong>. Please refer to <a class="reference external" href="https://aws.amazon.com/s3/">Amazon S3 service</a> for how to get access to Amazon S3.</p></li>
<li><p><strong>SageMaker Framework Containers</strong>. Please follow <a class="reference external" href="https://github.com/aws/deep-learning-containers">AWS Deep Learning Containers guideline</a> to get access to the image.</p></li>
<li><p><strong>Amazon EC2</strong> (optional). Please refer to <a class="reference external" href="https://aws.amazon.com/ec2/">Amazon EC2 service</a> for how to get access to Amazon EC2.</p></li>
</ul>
</section>
<section id="setup-graphstorm-sagemaker-docker-image">
<h2>Setup GraphStorm SageMaker Docker Image<a class="headerlink" href="#setup-graphstorm-sagemaker-docker-image" title="Permalink to this heading"></a></h2>
<p>GraphStorm uses SageMaker’s <strong>BYOC</strong> (Bring Your Own Container) mode. Therefore, before launching GraphStorm on SageMaker, there are two steps required to setup a GraphStorm SageMaker Docker image.</p>
<section id="step-1-build-a-sagemaker-compatible-docker-image">
<span id="build-sagemaker-docker"></span><h3>Step 1: Build a SageMaker-compatible Docker image<a class="headerlink" href="#step-1-build-a-sagemaker-compatible-docker-image" title="Permalink to this heading"></a></h3>
<div class="admonition note">
<p class="admonition-title">Note</p>
<ul class="simple">
<li><p>Please make sure your account has access key (AK) and security access key (SK) configured to authenticate accesses to AWS services.</p></li>
<li><p>For more details of Amazon ECR operation via CLI, users can refer to the <a class="reference external" href="https://docs.aws.amazon.com/AmazonECR/latest/userguide/getting-started-cli.html">Using Amazon ECR with the AWS CLI document</a>.</p></li>
</ul>
</div>
<p>First, in a Linux machine, configure a Docker environment by following the <a class="reference external" href="https://docs.docker.com/get-docker/">Docker documentation</a> suggestions.</p>
<p>In order to use the SageMaker base Docker image, users need to use the following command to authenticate to pull SageMaker images.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>aws<span class="w"> </span>ecr<span class="w"> </span>get-login-password<span class="w"> </span>--region<span class="w"> </span>us-east-1<span class="w"> </span><span class="p">|</span><span class="w"> </span>docker<span class="w"> </span>login<span class="w"> </span>--username<span class="w"> </span>AWS<span class="w"> </span>--password-stdin<span class="w"> </span><span class="m">763104351884</span>.dkr.ecr.us-east-1.amazonaws.com
</pre></div>
</div>
<p>Then, clone GraphStorm source code, and build a GraphStorm SageMaker compatible Docker image from source with commands:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>git<span class="w"> </span>clone<span class="w"> </span>https://github.com/awslabs/graphstorm.git

<span class="nb">cd</span><span class="w"> </span>/path-to-graphstorm/docker/

bash<span class="w"> </span>/path-to-graphstorm/docker/build_docker_sagemaker.sh<span class="w"> </span>/path-to-graphstorm/<span class="w"> </span>&lt;DOCKER_TYPE&gt;<span class="w"> </span>&lt;DOCKER_NAME&gt;<span class="w"> </span>&lt;DOCKER_TAG&gt;
</pre></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">build_docker_sagemaker.sh</span></code> script takes four arguments:</p>
<ol class="arabic simple">
<li><p><strong>path-to-graphstorm</strong> (<strong>required</strong>), is the absolute path of the <code class="docutils literal notranslate"><span class="pre">graphstorm</span></code> folder, where you cloned the GraphStorm source code. For example, the path could be <code class="docutils literal notranslate"><span class="pre">/code/graphstorm</span></code>.</p></li>
<li><p><strong>DOCKER_TYPE</strong> (optional), is the docker type of the to-be built Docker image. There are two options: <code class="docutils literal notranslate"><span class="pre">cpu</span></code> for building CPU-compatible images, and <code class="docutils literal notranslate"><span class="pre">gpu</span></code> for building Nvidia GPU-compatible images. Default is <code class="docutils literal notranslate"><span class="pre">gpu</span></code>.</p></li>
<li><p><strong>DOCKER_NAME</strong> (optional), is the assigned name of the to-be built Docker image. Default is <code class="docutils literal notranslate"><span class="pre">graphstorm</span></code>.</p></li>
</ol>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>In order to upload the GraphStorm SageMaker Docker image to Amazon ECR, users need to define the &lt;DOCKER_NAME&gt; to include the ECR URI string, <strong>&lt;AWS_ACCOUNT_ID&gt;.dkr.ecr.&lt;REGION&gt;.amazonaws.com/</strong>, e.g., <code class="docutils literal notranslate"><span class="pre">888888888888.dkr.ecr.us-east-1.amazonaws.com/graphstorm</span></code>.</p>
</div>
<ol class="arabic simple" start="4">
<li><p><strong>DOCKER_TAG</strong> (optional), is the assigned tag name of the to-be built Docker image. Default is <code class="docutils literal notranslate"><span class="pre">sm</span></code>.</p></li>
</ol>
<p>Once the <code class="docutils literal notranslate"><span class="pre">build_docker_sagemaker.sh</span></code> command completes successfully, there will be a Docker image, named <code class="docutils literal notranslate"><span class="pre">&lt;DOCKER_NAME&gt;:&lt;DOCKER_TAG&gt;</span></code>, such as <code class="docutils literal notranslate"><span class="pre">888888888888.dkr.ecr.us-east-1.amazonaws.com/graphstorm:sm</span></code>, in the local repository, which could be listed by running:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>docker<span class="w"> </span>image<span class="w"> </span>ls
</pre></div>
</div>
</section>
<section id="step-2-upload-docker-images-to-amazon-ecr-repository">
<span id="upload-sagemaker-docker"></span><h3>Step 2: Upload Docker Images to Amazon ECR Repository<a class="headerlink" href="#step-2-upload-docker-images-to-amazon-ecr-repository" title="Permalink to this heading"></a></h3>
<p>Because SageMaker relies on Amazon ECR to access customers’ own Docker images, users need to upload Docker images built in the Step 1 to their own ECR repository.</p>
<p>The following command will authenticate the user account to access to user’s ECR repository via AWS CLI.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>aws<span class="w"> </span>ecr<span class="w"> </span>get-login-password<span class="w"> </span>--region<span class="w"> </span>&lt;REGION&gt;<span class="w"> </span><span class="p">|</span><span class="w"> </span>docker<span class="w"> </span>login<span class="w"> </span>--username<span class="w"> </span>AWS<span class="w"> </span>--password-stdin<span class="w"> </span>&lt;AWS_ACCOUNT_ID&gt;.dkr.ecr.&lt;REGION&gt;.amazonaws.com
</pre></div>
</div>
<p>Please replace the <cite>&lt;REGION&gt;</cite> and <cite>&lt;AWS_ACCOUNT_ID&gt;</cite> with your own account information and be consistent with the values used in the <strong>Step 1</strong>.</p>
<p>In addition, users need to create an ECR repository at the specified <cite>&lt;REGION&gt;</cite> with the name as <cite>&lt;DOCKER_NAME&gt;</cite> <strong>WITHOUT</strong> the ECR URI string, e.g., <code class="docutils literal notranslate"><span class="pre">graphstorm</span></code>.</p>
<p>And then use the below command to push the built GraphStorm Docker image to users’ own ECR repository.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>docker<span class="w"> </span>push<span class="w"> </span>&lt;DOCKER_NAME&gt;:&lt;DOCKER_TAG&gt;
</pre></div>
</div>
<p>Please replace the <cite>&lt;DOCKER_NAME&gt;</cite> and <cite>&lt;DOCKER_TAG&gt;</cite> with the actual Docker image name and tag, e.g., <code class="docutils literal notranslate"><span class="pre">888888888888.dkr.ecr.us-east-1.amazonaws.com/graphstorm:sm</span></code>.</p>
</section>
</section>
<section id="run-graphstorm-on-sagemaker">
<h2>Run GraphStorm on SageMaker<a class="headerlink" href="#run-graphstorm-on-sagemaker" title="Permalink to this heading"></a></h2>
<p>There are two ways to run GraphStorm on SageMaker.</p>
<ul class="simple">
<li><p><strong>Run with Amazon SageMaker service</strong>. In this way, users will use GraphStorm’s tools to submit SageMaker API calls, which request SageMaker services to start new SageMaker training or inference instances that run GraphStorm code. Users can submit the API calls on a properly configured machine without GPUs (e.g., C5.xlarge). This is the formal way to run GraphStorm experiments on large graphs and to deploy GraphStorm on SageMaker for production environment.</p></li>
<li><p><strong>Run with Docker Compose in a local environment</strong>. In this way, users do not call the SageMaker service, but use Docker Compose to run SageMaker locally in a Linux instance that has GPUs. This is mainly for model developers and testers to simulate running GraphStorm on SageMaker.</p></li>
</ul>
<section id="run-graphstorm-with-amazon-sagemaker-service">
<h3>Run GraphStorm with Amazon SageMaker service<a class="headerlink" href="#run-graphstorm-with-amazon-sagemaker-service" title="Permalink to this heading"></a></h3>
<p>To run GraphStorm with the Amazon SageMaker service, users should set up an instance with the SageMaker library installed and GraphStorm’s SageMaker tools copied.</p>
<ol class="arabic simple">
<li><p>Use the below command to install SageMaker.</p></li>
</ol>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>pip<span class="w"> </span>install<span class="w"> </span>sagemaker
</pre></div>
</div>
<ol class="arabic simple" start="2">
<li><p>Copy GraphStorm SageMaker tools. Users can clone the GraphStorm repository using the following command or copy the <a class="reference external" href="https://github.com/awslabs/graphstorm/tree/main/sagemaker">sagemaker folder</a> to the instance.</p></li>
</ol>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>git<span class="w"> </span>clone<span class="w"> </span>https://github.com/awslabs/graphstorm.git
</pre></div>
</div>
<section id="prepare-graph-data">
<h4>Prepare graph data<a class="headerlink" href="#prepare-graph-data" title="Permalink to this heading"></a></h4>
<p>Unlike GraphStorm’s <a class="reference internal" href="../tutorials/quick-start.html#quick-start-standalone"><span class="std std-ref">Standalone mode</span></a> and <a class="reference internal" href="distributed.html#distributed-cluster"><span class="std std-ref">the Distributed mode</span></a>, which rely on local disk or shared file system to store the partitioned graph, SageMaker utilizes Amazon S3 as the shared data storage for distributing partitioned graphs and the configuration YAML file.</p>
<p>This tutorial uses the same three-partition OGB-MAG graph and the Link Prediction task as those introduced in the <a class="reference internal" href="distributed.html#partition-a-graph"><span class="std std-ref">Partition a Graph</span></a> section of the <a class="reference internal" href="distributed.html#distributed-cluster"><span class="std std-ref">Use GraphStorm in a Distributed Cluster</span></a> tutorial. After generating the partitioned OGB-MAG graphs, use the following commands to upload them and the configuration YAML file to an S3 bucket.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>aws<span class="w"> </span>s3<span class="w"> </span>cp<span class="w"> </span>--recursive<span class="w"> </span>/data/ogbn_mag_lp_3p<span class="w"> </span>s3://&lt;PATH_TO_DATA&gt;/ogbn_mag_lp_3p
aws<span class="w"> </span>s3<span class="w"> </span>cp<span class="w"> </span>/graphstorm/training_scripts/gsgnn_lp/mag_lp.yaml<span class="w"> </span>s3://&lt;PATH_TO_TRAINING_CONFIG&gt;/mag_lp.yaml
</pre></div>
</div>
<p>Please replace <cite>&lt;PATH_TO_DATA&gt;</cite> and <cite>&lt;PATH_TO_TRAINING_CONFIG&gt;</cite> with your own S3 bucket URI.</p>
</section>
<section id="launch-training">
<h4>Launch training<a class="headerlink" href="#launch-training" title="Permalink to this heading"></a></h4>
<p>Launching GraphStorm training on SageMaker is similar as launching in the <a class="reference internal" href="../tutorials/quick-start.html#quick-start-standalone"><span class="std std-ref">Standalone mode</span></a> and <a class="reference internal" href="distributed.html#distributed-cluster"><span class="std std-ref">the Distributed mode</span></a>, except for three diffences:</p>
<ul class="simple">
<li><p>The launch commands are located in the <code class="docutils literal notranslate"><span class="pre">graphstorm/sagemaker</span></code> folder, and</p></li>
<li><p>Users need to provide AWS service-related information in the command.</p></li>
<li><p>All paths for saving models, embeddings, and prediction results should be specified as S3 locations using the S3 related arguments.</p></li>
</ul>
<p>Users can use the following commands to launch a GraphStorm Link Prediction training job with the OGB-MAG graph.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span><span class="w"> </span>/path-to-graphstorm/sagemaker/

python3<span class="w"> </span>launch/launch_train.py<span class="w"> </span><span class="se">\</span>
<span class="w">        </span>--image-url<span class="w"> </span>&lt;AMAZON_ECR_IMAGE_URI&gt;<span class="w"> </span><span class="se">\</span>
<span class="w">        </span>--region<span class="w"> </span>&lt;REGION&gt;<span class="w"> </span><span class="se">\</span>
<span class="w">        </span>--entry-point<span class="w"> </span>run/train_entry.py<span class="w"> </span><span class="se">\</span>
<span class="w">        </span>--role<span class="w"> </span>&lt;ROLE_ARN&gt;<span class="w"> </span><span class="se">\</span>
<span class="w">        </span>--instance-count<span class="w"> </span><span class="m">3</span><span class="w"> </span><span class="se">\</span>
<span class="w">        </span>--graph-data-s3<span class="w"> </span>s3://&lt;PATH_TO_DATA&gt;/ogbn_mag_lp_3p<span class="w"> </span><span class="se">\</span>
<span class="w">        </span>--yaml-s3<span class="w"> </span>s3://&lt;PATH_TO_TRAINING_CONFIG&gt;/mag_lp.yaml<span class="w"> </span><span class="se">\</span>
<span class="w">        </span>--model-artifact-s3<span class="w"> </span>s3://&lt;PATH_TO_SAVE_TRAINED_MODEL&gt;/<span class="w"> </span><span class="se">\</span>
<span class="w">        </span>--graph-name<span class="w"> </span>ogbn-mag<span class="w"> </span><span class="se">\</span>
<span class="w">        </span>--task-type<span class="w"> </span>link_prediction<span class="w"> </span><span class="se">\</span>
<span class="w">        </span>--lp-decoder-type<span class="w"> </span>dot_product<span class="w"> </span><span class="se">\</span>
<span class="w">        </span>--num-layers<span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">        </span>--fanout<span class="w"> </span><span class="m">10</span><span class="w"> </span><span class="se">\</span>
<span class="w">        </span>--hidden-size<span class="w"> </span><span class="m">128</span><span class="w"> </span><span class="se">\</span>
<span class="w">        </span>--backend<span class="w"> </span>gloo<span class="w"> </span><span class="se">\</span>
<span class="w">        </span>--batch-size<span class="w"> </span><span class="m">128</span>
</pre></div>
</div>
<p>Please replace <cite>&lt;AMAZON_ECR_IMAGE_URI&gt;</cite> with the <cite>&lt;DOCKER_NAME&gt;:&lt;DOCKER_TAG&gt;</cite> that are uploaded in the Step 2, e.g., <code class="docutils literal notranslate"><span class="pre">888888888888.dkr.ecr.us-east-1.amazonaws.com/graphstorm:sm</span></code>, replace the <cite>&lt;REGION&gt;</cite> with the region where ECR image repository is located, e.g., <code class="docutils literal notranslate"><span class="pre">us-east-1</span></code>, and replace the <cite>&lt;ROLE_ARN&gt;</cite> with your AWS account ARN that has SageMaker execution role, e.g., <code class="docutils literal notranslate"><span class="pre">&quot;arn:aws:iam::&lt;ACCOUNT_ID&gt;:role/service-role/AmazonSageMaker-ExecutionRole-20220627T143571&quot;</span></code>.</p>
<p>Because we are using a three-partition OGB-MAG graph, we need to set the <code class="docutils literal notranslate"><span class="pre">--instance-count</span></code> to 3 in this command.</p>
<p>The trained model artifact will be stored in the S3 location provided through the <code class="docutils literal notranslate"><span class="pre">--model-artifact-s3</span></code> argument. You can use the following command to check the model artifacts after the training completes.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>aws<span class="w"> </span>s3<span class="w"> </span>ls<span class="w"> </span>s3://&lt;PATH_TO_SAVE_TRAINED_MODEL&gt;/
</pre></div>
</div>
</section>
<section id="launch-inference">
<h4>Launch inference<a class="headerlink" href="#launch-inference" title="Permalink to this heading"></a></h4>
<p>Users can use the following command to launch a GraphStorm Link Prediction inference job on the OGB-MAG graph.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python3<span class="w"> </span>launch/launch_infer.py<span class="w"> </span><span class="se">\</span>
<span class="w">        </span>--image-url<span class="w"> </span>&lt;AMAZON_ECR_IMAGE_URI&gt;<span class="w"> </span><span class="se">\</span>
<span class="w">        </span>--region<span class="w"> </span>&lt;REGION&gt;<span class="w"> </span><span class="se">\</span>
<span class="w">        </span>--entry-point<span class="w"> </span>run/infer_entry.py<span class="w"> </span><span class="se">\</span>
<span class="w">        </span>--role<span class="w"> </span>&lt;ROLE_ARN&gt;<span class="w"> </span><span class="se">\</span>
<span class="w">        </span>--instance-count<span class="w"> </span><span class="m">3</span><span class="w"> </span><span class="se">\</span>
<span class="w">        </span>--graph-data-s3<span class="w"> </span>s3://&lt;PATH_TO_DATA&gt;/ogbn_mag_lp_3p<span class="w"> </span><span class="se">\</span>
<span class="w">        </span>--yaml-s3<span class="w"> </span>s3://&lt;PATH_TO_TRAINING_CONFIG&gt;/mag_lp.yaml<span class="w"> </span><span class="se">\</span>
<span class="w">        </span>--model-artifact-s3<span class="w"> </span>s3://&lt;PATH_TO_SAVE_TRAINED_MODEL&gt;/<span class="w"> </span><span class="se">\</span>
<span class="w">        </span>--output-emb-s3<span class="w"> </span>s3://&lt;PATH_TO_SAVE_GENERATED_NODE_EMBEDDING&gt;/<span class="w"> </span><span class="se">\</span>
<span class="w">        </span>--output-prediction-s3<span class="w"> </span>s3://&lt;PATH_TO_SAVE_PREDICTION_RESULTS&gt;<span class="w"> </span><span class="se">\</span>
<span class="w">        </span>--graph-name<span class="w"> </span>ogbn-mag<span class="w"> </span><span class="se">\</span>
<span class="w">        </span>--task-type<span class="w"> </span>link_prediction<span class="w"> </span><span class="se">\</span>
<span class="w">        </span>--num-layers<span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">        </span>--fanout<span class="w"> </span><span class="m">10</span><span class="w"> </span><span class="se">\</span>
<span class="w">        </span>--hidden-size<span class="w"> </span><span class="m">128</span><span class="w"> </span><span class="se">\</span>
<span class="w">        </span>--backend<span class="w"> </span>gloo<span class="w"> </span><span class="se">\</span>
<span class="w">        </span>--batch-size<span class="w"> </span><span class="m">128</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Diffferent from the training command’s argument, in the inference command, the value of the <code class="docutils literal notranslate"><span class="pre">--model-artifact-s3</span></code> argument needs to be path to a saved model. By default, it is stored under an S3 path with specific training epoch or epoch plus iteration number, e.g., <code class="docutils literal notranslate"><span class="pre">s3://models/epoch-0-iter-999</span></code>, where the trained model artifacts were saved.</p>
</div>
<p>As the outcomes of the inference command, the generated node embeddings will be uploaded to <code class="docutils literal notranslate"><span class="pre">s3://&lt;PATH_TO_SAVE_GENERATED_NODE_EMBEDDING&gt;/</span></code>. For node classification/regression or edge classification/regression tasks, users can use <code class="docutils literal notranslate"><span class="pre">--output-prediction-s3</span></code> to specify the saving locations of prediction results.</p>
<p>Users can use the following commands to check the corresponding outputs:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>aws<span class="w"> </span>s3<span class="w"> </span>ls<span class="w"> </span>s3://&lt;PATH_TO_SAVE_GENERATED_NODE_EMBEDDING&gt;/
aws<span class="w"> </span>s3<span class="w"> </span>ls<span class="w"> </span>s3://&lt;PATH_TO_SAVE_PREDICTION_RESULTS&gt;/
</pre></div>
</div>
</section>
</section>
<section id="run-graphstorm-sagemaker-with-docker-compose">
<h3>Run GraphStorm SageMaker with Docker Compose<a class="headerlink" href="#run-graphstorm-sagemaker-with-docker-compose" title="Permalink to this heading"></a></h3>
<p>This section describes how to launch Docker compose jobs that emulate a SageMaker training execution environment. This can be used to develop and test GraphStorm model training and inference on SageMaker locally.</p>
<p>If users have never worked with Docker compose before the official description provides a great intro:</p>
<div class="admonition hint">
<p class="admonition-title">Hint</p>
<p>Compose is a tool for defining and running multi-container Docker applications. With Compose, you use a YAML file to configure your application’s services. Then, with a single command, you create and start all the services from your configuration.</p>
</div>
<p>We will use this capability to launch multiple worker instances locally, that will be configured to “look like” a SageMaker training instance and communicate over a virtual network created by Docker Compose. This way our test environment will be as close to a real SageMaker distributed job as we can get, without needing to launch SageMaker jobs, or launch and configure multiple EC2 instances when developing features.</p>
<section id="get-started">
<h4>Get Started<a class="headerlink" href="#get-started" title="Permalink to this heading"></a></h4>
<p>To run GraphStorm SageMaker with Docker Compose, we need to set up a local Linux instance with the following contents.</p>
<ol class="arabic simple">
<li><p>Use the below command to install SageMaker.</p></li>
</ol>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>pip<span class="w"> </span>install<span class="w"> </span>sagemaker
</pre></div>
</div>
<ol class="arabic simple" start="2">
<li><p>Clone GraphStorm code.</p></li>
</ol>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>git<span class="w"> </span>clone<span class="w"> </span>https://github.com/awslabs/graphstorm.git
</pre></div>
</div>
<ol class="arabic simple" start="3">
<li><p>Setup GraphStorm in the PYTHONPATH variable.</p></li>
</ol>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">export</span><span class="w"> </span><span class="nv">PYTHONPATH</span><span class="o">=</span>/PATH_TO_GRAPHSTORM/python:<span class="nv">$PYTHONPATH</span>
</pre></div>
</div>
<ol class="arabic simple" start="4">
<li><p>Build a SageMaker compatible Docker image following the <a class="reference internal" href="#build-sagemaker-docker"><span class="std std-ref">Step 1</span></a>.</p></li>
<li><p>Follow the <a class="reference external" href="https://docs.docker.com/compose/install/linux/">Docker Compose</a> documentation to install Docker Compose.</p></li>
</ol>
</section>
<section id="generate-a-docker-compose-file">
<h4>Generate a Docker Compose file<a class="headerlink" href="#generate-a-docker-compose-file" title="Permalink to this heading"></a></h4>
<p>A Docker Compose file is a YAML file that tells Docker which containers to spin up and how to configure them. To launch the services with a Docker Compose file, we can use <code class="docutils literal notranslate"><span class="pre">docker</span> <span class="pre">compose</span> <span class="pre">-f</span> <span class="pre">docker-compose.yaml</span> <span class="pre">up</span></code>. This will launch the container and execute its entry point.</p>
<p>To emulate a SageMaker distributed execution environment based on the previously built Docker image (suppose the docker image is named <code class="docutils literal notranslate"><span class="pre">graphstorm:sm</span></code>), you would need a Docker Compose file that resembles the following:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">version</span><span class="p">:</span><span class="w"> </span><span class="s">&#39;3.7&#39;</span>

<span class="nt">networks</span><span class="p">:</span>
<span class="nt">gfs</span><span class="p">:</span>
<span class="w">    </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">gsf-network</span>

<span class="nt">services</span><span class="p">:</span>
<span class="nt">algo-1</span><span class="p">:</span>
<span class="w">    </span><span class="nt">image</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">graphstorm:sm</span>
<span class="w">    </span><span class="nt">container_name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">algo-1</span>
<span class="w">    </span><span class="nt">hostname</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">algo-1</span>
<span class="w">    </span><span class="nt">networks</span><span class="p">:</span>
<span class="w">    </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">gsf</span>
<span class="w">    </span><span class="nt">command</span><span class="p">:</span><span class="w"> </span><span class="s">&#39;xxx&#39;</span>
<span class="w">    </span><span class="nt">environment</span><span class="p">:</span>
<span class="w">    </span><span class="nt">SM_TRAINING_ENV</span><span class="p">:</span><span class="w"> </span><span class="s">&#39;{&quot;hosts&quot;:</span><span class="nv"> </span><span class="s">[&quot;algo-1&quot;,</span><span class="nv"> </span><span class="s">&quot;algo-2&quot;,</span><span class="nv"> </span><span class="s">&quot;algo-3&quot;,</span><span class="nv"> </span><span class="s">&quot;algo-4&quot;],</span><span class="nv"> </span><span class="s">&quot;current_host&quot;:</span><span class="nv"> </span><span class="s">&quot;algo-1&quot;}&#39;</span>
<span class="w">    </span><span class="nt">WORLD_SIZE</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">4</span>
<span class="w">    </span><span class="nt">MASTER_ADDR</span><span class="p">:</span><span class="w"> </span><span class="s">&#39;algo-1&#39;</span>
<span class="w">    </span><span class="nt">AWS_REGION</span><span class="p">:</span><span class="w"> </span><span class="s">&#39;us-west-2&#39;</span>
<span class="w">    </span><span class="nt">ports</span><span class="p">:</span>
<span class="w">    </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">22</span>
<span class="w">    </span><span class="nt">working_dir</span><span class="p">:</span><span class="w"> </span><span class="s">&#39;/opt/ml/code/&#39;</span>

<span class="nt">algo-2</span><span class="p">:</span>
<span class="w">    </span><span class="p p-Indicator">[</span><span class="nv">...</span><span class="p p-Indicator">]</span>
</pre></div>
</div>
<p>Some explanation on the above elements (see the <a class="reference external" href="https://docs.docker.com/compose/compose-file/">official docs</a> for more details):</p>
<ul class="simple">
<li><p><strong>image</strong>: Specifies the Docker image that will be used for launching the container. In this case, the image is <code class="docutils literal notranslate"><span class="pre">graphstorm:sm</span></code>, which should correspond to the previously built Docker image.</p></li>
<li><p><strong>environment</strong>: Sets the environment variables for the container.</p></li>
<li><p><strong>command</strong>: Specifies the entry point, i.e., the command that will be executed when the container launches. In this case, /path/to/entrypoint.sh is the command that will be executed.</p></li>
</ul>
<p>To help users generate yaml file automatically, GraphStorm provides a Python script, <code class="docutils literal notranslate"><span class="pre">generate_sagemaker_docker_compose.py</span></code>, that builds the docker compose file for users.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The script uses the <a class="reference external" href="https://pypi.org/project/PyYAML/">PyYAML</a> library. Please use the below commnd to install it.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>pip<span class="w"> </span>install<span class="w"> </span>pyyaml
</pre></div>
</div>
</div>
<p>This Python script has 4 required arguments that determine the Docker Compose file that will be generated:</p>
<ul class="simple">
<li><p><strong>–aws-access-key-id</strong>: The AWS access key ID for accessing S3 data within docker</p></li>
<li><p><strong>–aws-secret-access-key</strong>: The AWS secret access key for accessing S3 data within docker.</p></li>
<li><p><strong>–aws-session-token</strong>: The AWS session toekn used for accessing S3 data within docker.</p></li>
<li><p><strong>–num-instances</strong>: The number of instances we want to launch. This will determine the number of algo-x services entries our compose file ends up with.</p></li>
</ul>
<p>The rest of the arguments are passed on to <code class="docutils literal notranslate"><span class="pre">sagemaker_train.py</span></code> or <code class="docutils literal notranslate"><span class="pre">sagemaker_infer.py</span></code>:</p>
<ul class="simple">
<li><p><strong>–task-type</strong>: Task type.</p></li>
<li><p><strong>–graph-data-s3</strong>: S3 location of the input graph.</p></li>
<li><p><strong>–graph-name</strong>: Name of the input graph.</p></li>
<li><p><strong>–yaml-s3</strong>: S3 location of yaml file for training and inference.</p></li>
<li><p><strong>–custom-script</strong>: Custom training script provided by customers to run customer training logic. This should be a path to the Python script within the Docker image.</p></li>
<li><p><strong>–output-emb-s3</strong>: S3 location to store GraphStorm generated node embeddings. This is an inference only argument.</p></li>
<li><p><strong>–output-prediction-s3</strong>: S3 location to store prediction results. This is an inference only argument.</p></li>
</ul>
</section>
<section id="run-graphstorm-on-docker-compose-for-training">
<h4>Run GraphStorm on Docker Compose for Training<a class="headerlink" href="#run-graphstorm-on-docker-compose-for-training" title="Permalink to this heading"></a></h4>
<p>First, use the following command to generate a Compose YAML file for the Link Prediction training on OGB-MAG graph.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python3<span class="w"> </span>generate_sagemaker_docker_compose.py<span class="w"> </span><span class="se">\</span>
<span class="w">        </span>--aws-access-key<span class="w"> </span><span class="s">&lt;&lt;AWS_ACCESS_KEY&gt;&gt; \</span>
<span class="s">        --aws-secret-access-key &lt;AWS_</span>SECRET_ACCESS_KEY&gt;<span class="w"> </span><span class="se">\</span>
<span class="w">        </span>--aws-session-token<span class="w"> </span>&lt;AWS_SESSION_TOKEN&gt;<span class="w"> </span><span class="se">\</span>
<span class="w">        </span>--num-instances<span class="w"> </span><span class="m">3</span><span class="w"> </span><span class="se">\</span>
<span class="w">        </span>--image<span class="w"> </span>&lt;GRAPHSTORM_DOCKER_IMAGE&gt;<span class="w"> </span><span class="se">\</span>
<span class="w">        </span>--graph-data-s3<span class="w"> </span>s3://&lt;PATH_TO_DATA&gt;/ogbn_mag_lp_3p<span class="w"> </span><span class="se">\</span>
<span class="w">        </span>--yaml-s3<span class="w"> </span>s3://&lt;PATH_TO_TRAINING_CONFIG&gt;/map_lp.yaml<span class="w"> </span><span class="se">\</span>
<span class="w">        </span>--model-artifact-s3<span class="w"> </span>s3://&lt;PATH_TO_SAVE_TRAINED_MODEL&gt;<span class="w"> </span><span class="se">\</span>
<span class="w">        </span>--graph-name<span class="w"> </span>ogbn-mag<span class="w"> </span><span class="se">\</span>
<span class="w">        </span>--task-type<span class="w"> </span>link_prediction<span class="w"> </span><span class="se">\</span>
<span class="w">        </span>--num-layers<span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">        </span>--fanout<span class="w"> </span><span class="m">10</span><span class="w"> </span><span class="se">\</span>
<span class="w">        </span>--hidden-size<span class="w"> </span><span class="m">128</span><span class="w"> </span><span class="se">\</span>
<span class="w">        </span>--backend<span class="w"> </span>gloo<span class="w"> </span><span class="se">\</span>
<span class="w">        </span>--batch-size<span class="w"> </span><span class="m">128</span>
</pre></div>
</div>
<p>The above command will create a Docker Compose file named <code class="docutils literal notranslate"><span class="pre">docker-compose-&lt;task-type&gt;-&lt;num-instances&gt;-train.yaml</span></code>, which we can then use to launch the job.</p>
<p>As our Docker Compose will use a Docker network, named <code class="docutils literal notranslate"><span class="pre">gsf-network</span></code>, for inter-container communications, users need to run the following command to create the network before luanch Docker Compose.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>docker<span class="w"> </span>network<span class="w"> </span>create<span class="w"> </span><span class="s2">&quot;gsf-network&quot;</span>
</pre></div>
</div>
<p>Then, use the following command to run the Link Prediction training on OGB-MAG graph.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>docker<span class="w"> </span>compose<span class="w"> </span>-f<span class="w"> </span>docker-compose-link_prediction-3-train.yaml<span class="w"> </span>up
</pre></div>
</div>
<p>Running the above command will launch 3 instances of the image, configured with the command and env vars that emulate a SageMaker execution environment and run the <code class="docutils literal notranslate"><span class="pre">sagemaker_train.py</span></code> script.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The containers actually interact with S3, so the provided AWS assess key, security access key, and session token should be valid for access S3 bucket.</p>
</div>
</section>
<section id="run-graphstorm-on-docker-compose-for-inference">
<h4>Run GraphStorm on Docker Compose for Inference<a class="headerlink" href="#run-graphstorm-on-docker-compose-for-inference" title="Permalink to this heading"></a></h4>
<p>The <code class="docutils literal notranslate"><span class="pre">generate_sagemaker_docker_compose.py</span></code> can build Compose file for the inference task with the same arguments as for training, and in addition, but add a new argument, <code class="docutils literal notranslate"><span class="pre">--inference</span></code>. The below command create the Compose file for the Link Prediction inference on OGB-MAG graph.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python3<span class="w"> </span>generate_sagemaker_docker_compose.py<span class="w"> </span><span class="se">\</span>
<span class="w">        </span>--aws-access-key<span class="w"> </span><span class="s">&lt;&lt;AWS_ACCESS_KEY&gt;&gt; \</span>
<span class="s">        --aws-secret-access-key &lt;AWS_</span>SECRET_ACCESS_KEY&gt;<span class="w"> </span><span class="se">\</span>
<span class="w">        </span>--aws-session-token<span class="w"> </span>&lt;AWS_SESSION_TOKEN&gt;<span class="w"> </span><span class="se">\</span>
<span class="w">        </span>--num-instances<span class="w"> </span><span class="m">3</span><span class="w"> </span><span class="se">\</span>
<span class="w">        </span>--image<span class="w"> </span>&lt;GRAPHSTORM_DOCKER_IMAGE&gt;<span class="w"> </span><span class="se">\</span>
<span class="w">        </span>--graph-data-s3<span class="w"> </span>s3://&lt;PATH_TO_DATA&gt;/ogbn_mag_lp_3p<span class="w"> </span><span class="se">\</span>
<span class="w">        </span>--yaml-s3<span class="w"> </span>s3://&lt;PATH_TO_TRAINING_CONFIG&gt;/map_lp.yaml<span class="w"> </span><span class="se">\</span>
<span class="w">        </span>--model-artifact-s3<span class="w"> </span>s3://&lt;PATH_TO_SAVE_TRAINED_MODEL&gt;<span class="w"> </span><span class="se">\</span>
<span class="w">        </span>--graph-name<span class="w"> </span>ogbn-mag<span class="w"> </span><span class="se">\</span>
<span class="w">        </span>--task-type<span class="w"> </span>link_prediction<span class="w"> </span><span class="se">\</span>
<span class="w">        </span>--num-layers<span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">        </span>--fanout<span class="w"> </span><span class="m">10</span><span class="w"> </span><span class="se">\</span>
<span class="w">        </span>--hidden-size<span class="w"> </span><span class="m">128</span><span class="w"> </span><span class="se">\</span>
<span class="w">        </span>--backend<span class="w"> </span>gloo<span class="w"> </span><span class="se">\</span>
<span class="w">        </span>--batch-size<span class="w"> </span><span class="m">128</span><span class="w"> </span><span class="se">\</span>
<span class="w">        </span>--inference
</pre></div>
</div>
<p>The command will create a Docker compose file named <code class="docutils literal notranslate"><span class="pre">docker-compose-&lt;task-type&gt;-&lt;num-instances&gt;-infer.yaml</span></code>. And then, we can use the same command to spin up the inference job.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>docker<span class="w"> </span>compose<span class="w"> </span>-f<span class="w"> </span>docker-compose-link_prediction-3-infer.yaml<span class="w"> </span>up
</pre></div>
</div>
</section>
<section id="clean-up">
<h4>Clean Up<a class="headerlink" href="#clean-up" title="Permalink to this heading"></a></h4>
<p>To save computing resources, users can run the below command to clean up the Docker Compose environment.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>docker<span class="w"> </span>compose<span class="w"> </span>-f<span class="w"> </span>docker-compose-file<span class="w"> </span>down
</pre></div>
</div>
</section>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="distributed.html" class="btn btn-neutral float-left" title="Use GraphStorm in a Distributed Cluster" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="../advanced/own-models.html" class="btn btn-neutral float-right" title="Use Your Own Models" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023, AGML team.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>