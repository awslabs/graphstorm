<!doctype html>
<html class="no-js" lang="en">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />
<link rel="index" title="Index" href="../genindex.html" /><link rel="search" title="Search" href="../search.html" /><link rel="next" title="Use GraphStorm on SageMaker" href="sagemaker.html" /><link rel="prev" title="Training and Inference" href="../configuration/configuration-run.html" />

    <!-- Generated with Sphinx 6.1.3 and Furo 2023.03.27 -->
        <title>Use GraphStorm in a Distributed Cluster - GraphStorm 0.1 documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo.css?digest=fad236701ea90a88636c2a8c73b44ae642ed2a53" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo-extensions.css?digest=30d1aed668e5c3a91c3e3bf6a60b675221979f0e" />
    
    


<style>
  body {
    --color-code-background: #f8f8f8;
  --color-code-foreground: black;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
      }
    }
  }
</style></head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-half" viewBox="0 0 24 24">
    <title>Auto light/dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-shadow">
      <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
      <circle cx="12" cy="12" r="9" />
      <path d="M13 12h5" />
      <path d="M13 15h4" />
      <path d="M13 18h1" />
      <path d="M13 9h4" />
      <path d="M13 6h1" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation">
  <div class="visually-hidden">Hide navigation sidebar</div>
</label>
<label class="overlay toc-overlay" for="__toc">
  <div class="visually-hidden">Hide table of contents sidebar</div>
</label>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <div class="visually-hidden">Toggle site navigation sidebar</div>
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="../index.html"><div class="brand">GraphStorm 0.1 documentation</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle">
          <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
          <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon" for="__toc">
        <div class="visually-hidden">Toggle table of contents sidebar</div>
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand" href="../index.html">
  
  
  <span class="sidebar-brand-text">GraphStorm 0.1 documentation</span>
  
</a><form class="sidebar-search-container" method="get" action="../search.html" role="search">
  <input class="sidebar-search" placeholder="Search" name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <p class="caption" role="heading"><span class="caption-text">Get Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../install/env-setup.html">Environment Setup</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/quick-start.html">Standalone Mode Quick Start Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/own-data.html">Use Your Own Data Tutorial</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../configuration/index.html">GraphStorm Configurations</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" role="switch" type="checkbox"/><label for="toctree-checkbox-1"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../configuration/configuration-gconstruction.html">Graph Construction</a></li>
<li class="toctree-l2"><a class="reference internal" href="../configuration/configuration-partition.html">Graph Partition</a></li>
<li class="toctree-l2"><a class="reference internal" href="../configuration/configuration-run.html">Training and Inference</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Scale to Giant Graphs</span></p>
<ul class="current">
<li class="toctree-l1 current current-page"><a class="current reference internal" href="#">Use GraphStorm in a Distributed Cluster</a></li>
<li class="toctree-l1"><a class="reference internal" href="sagemaker.html">Use GraphStorm on SageMaker</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Advanced Topics</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../advanced/own-models.html">Use Your Own Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/language-models.html">Use Text as Node Features</a></li>
</ul>

</div>
</div>

      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          
<div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle">
              <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
              <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon" for="__toc">
            <div class="visually-hidden">Toggle table of contents sidebar</div>
            <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
          </label>
        </div>
        <article role="main">
          <section id="use-graphstorm-in-a-distributed-cluster">
<span id="distributed-cluster"></span><h1>Use GraphStorm in a Distributed Cluster<a class="headerlink" href="#use-graphstorm-in-a-distributed-cluster" title="Permalink to this heading">#</a></h1>
<p>GraphStorm can scale to the enterprise-level graphs in the distributed mode by using a cluster of instances. To leverage this capacity, there are four steps to follow:</p>
<ul class="simple">
<li><p>Create a cluster with instances each of which can run GraphStorm Docker container.</p></li>
<li><p>Set up the IP address file and check port 2222 status.</p></li>
<li><p>Partition large graphs into distributed format.</p></li>
<li><p>Launch the training command within one instance’ container.</p></li>
</ul>
<p>The first section of this tutorial uses the <a class="reference external" href="https://ogb.stanford.edu/docs/nodeprop/#ogbn-mag">OGB-MAG</a> as an example data to demonstrate how to use GraphStorm to train an RGCN model (a built-in model) in a cluster with three EC2 instances. The OGB-MAG data is large enough to demonstrate the scalability of GraphStorm, and also small enough to complete training in short time.</p>
<section id="create-a-graphstorm-cluster">
<h2>Create a GraphStorm Cluster<a class="headerlink" href="#create-a-graphstorm-cluster" title="Permalink to this heading">#</a></h2>
<section id="setup-the-instance-of-a-cluster">
<h3>Setup the instance of a cluster<a class="headerlink" href="#setup-the-instance-of-a-cluster" title="Permalink to this heading">#</a></h3>
<p>A cluster contains several GPU installed instances each of which can run GraphStorm Docker container. For each instance, please follow the <a class="reference internal" href="../install/env-setup.html#setup"><span class="std std-ref">Environment Setup</span></a> description to setup GraphStorm Docker container environment. This tutorial uses three EC2 instances in the cluster.</p>
</section>
<section id="setup-of-a-shared-file-system-for-the-cluster">
<h3>Setup of a shared file system for the cluster<a class="headerlink" href="#setup-of-a-shared-file-system-for-the-cluster" title="Permalink to this heading">#</a></h3>
<p>A cluster requires a shared file system, such as NFS or EFS, mounted to each instance in the cluster, in which all GraphStorm containers in the cluster can share data files, and save model artifacts and prediction results.</p>
<p><a class="reference external" href="https://github.com/dmlc/dgl/tree/master/examples/pytorch/graphsage/dist#step-0-setup-a-distributed-file-system">Here</a> is the instruction of setting up NFS for a cluster provided by DGL. As the steps of setup of an NFS could be various for different systems, we suggest users to look for additional information about NFS setting. Here are some available resources: <a class="reference external" href="https://www.digitalocean.com/community/tutorials/how-to-set-up-an-nfs-mount-on-ubuntu-22-04">NFS tutorial</a> by DigitalOcean, <a class="reference external" href="https://ubuntu.com/server/docs/service-nfs">NFS document</a> for Ubuntu, <a class="reference external" href="https://www.linode.com/docs/guides/using-an-nfs-server-on-ubuntu2004/">NFS guide</a> by Linode, <a class="reference external" href="https://www.tecmint.com/how-to-setup-nfs-server-in-linux/">NFS tutorial</a> at Tecmint, and <a class="reference external" href="https://www.howtoforge.com/how-to-install-nfs-server-and-client-on-ubuntu-22-04/">NFS guide</a> by HowtoForge.</p>
<p>For an AWS EC2 cluster, users can also use EFS as the shared file system. Please follow 1) <a class="reference external" href="https://docs.aws.amazon.com/efs/latest/ug/gs-step-two-create-efs-resources.html">the instruction of creating EFS</a>; 2) <a class="reference external" href="https://docs.aws.amazon.com/efs/latest/ug/installing-amazon-efs-utils.html">the instruction of installing an EFS client</a>; and 3) <a class="reference external" href="https://docs.aws.amazon.com/efs/latest/ug/efs-mount-helper.html">the instructions of mounting the EFS filesystem</a> to set up EFS.</p>
<p>After setting up a shared file system, we can keep all partitioned graph data in the shared folder. Then mount the data folder to the <code class="docutils literal notranslate"><span class="pre">/path_to_data/</span></code> of each instances in the cluster so that all GraphStorm containers in the cluster can access these partitioned graph data easily.</p>
</section>
<section id="create-graphstorm-container-by-mounting-the-nfs-folder">
<h3>Create GraphStorm container by mounting the NFS folder<a class="headerlink" href="#create-graphstorm-container-by-mounting-the-nfs-folder" title="Permalink to this heading">#</a></h3>
<p>In each instance, use the following command to start a GraphStorm Docker container and run it as a backend daemon.</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>nvidia-docker<span class="w"> </span>run<span class="w"> </span>-v<span class="w"> </span>/path_to_data/:/data<span class="w"> </span><span class="se">\</span>
<span class="w">                  </span>-v<span class="w"> </span>/dev/shm:/dev/shm<span class="w"> </span><span class="se">\</span>
<span class="w">                  </span>--network<span class="o">=</span>host<span class="w"> </span><span class="se">\</span>
<span class="w">                  </span>-d<span class="w"> </span>--name<span class="w"> </span><span class="nb">test</span><span class="w"> </span>graphstorm:local
</pre></div>
</div>
<p>This command mount the shared <code class="docutils literal notranslate"><span class="pre">/path_to_data/</span></code> folder to each container’s <code class="docutils literal notranslate"><span class="pre">/data/</span></code> folder by which GraphStorm codes can access graph data and save training and inference outcomes.</p>
</section>
</section>
<section id="setup-the-ip-address-file-and-check-port-status">
<h2>Setup the IP address file and check port status<a class="headerlink" href="#setup-the-ip-address-file-and-check-port-status" title="Permalink to this heading">#</a></h2>
<section id="collect-the-ip-list">
<h3>Collect the IP list<a class="headerlink" href="#collect-the-ip-list" title="Permalink to this heading">#</a></h3>
<p>The GraphStorm Docker containers use SSH on port <code class="docutils literal notranslate"><span class="pre">2222</span></code> to communicate with each other. Users need to collect all IP addresses of the three instances and put them into a text file, e.g., <code class="docutils literal notranslate"><span class="pre">/data/ip_list.txt</span></code>, which is like:</p>
<figure class="align-center">
<img alt="../_images/distributed_ips.png" src="../_images/distributed_ips.png" />
</figure>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If possible, use <strong>private IP addresses</strong>, insteand of public IP addresses. Public IP addresses may have additional port constraints, which cause communication issues.</p>
</div>
<p>Put this file into container’s <code class="docutils literal notranslate"><span class="pre">/data/</span></code> folder.</p>
</section>
<section id="check-port">
<h3>Check port<a class="headerlink" href="#check-port" title="Permalink to this heading">#</a></h3>
<p>The GraphStorm Docker container uses port <code class="docutils literal notranslate"><span class="pre">2222</span></code> to <strong>ssh</strong> to containers running on other machines without passwords. Please make sure all host instances do not use this port.</p>
<p>Users also need to make sure the port <code class="docutils literal notranslate"><span class="pre">2222</span></code> is open for <strong>ssh</strong> commands.</p>
<p>Pick one instance and run the following command to connect to the GraphStorm Docker container.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>docker<span class="w"> </span>container<span class="w"> </span><span class="nb">exec</span><span class="w"> </span>-it<span class="w"> </span><span class="nb">test</span><span class="w"> </span>/bin/bash
</pre></div>
</div>
<p>In the container environment, users can check the connectivity with the command <code class="docutils literal notranslate"><span class="pre">ssh</span> <span class="pre">&lt;ip-in-the-cluster&gt;</span> <span class="pre">-p</span> <span class="pre">2222</span></code>. Please replacing the <code class="docutils literal notranslate"><span class="pre">&lt;ip-in-the-cluster&gt;</span></code> with the real IP address in the <code class="docutils literal notranslate"><span class="pre">ip_list.txt</span></code> file above, e.g.,</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>ssh<span class="w"> </span><span class="m">172</span>.38.12.143<span class="w"> </span>-p<span class="w"> </span><span class="m">2222</span>
</pre></div>
</div>
<p>If succeeds, you should login to the container in the <code class="docutils literal notranslate"><span class="pre">&lt;ip-in-the-cluster&gt;</span></code> instance.</p>
<p>If not, please make sure there is no limitation of port 2222.</p>
<p>For distributed training, users also need to make sure ports under 65536 is open for DistDGL to use.</p>
</section>
</section>
<section id="partition-a-graph">
<span id="id3"></span><h2>Partition a Graph<a class="headerlink" href="#partition-a-graph" title="Permalink to this heading">#</a></h2>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>All commands below should be run in a GraphStorm Docker container. Please refer to the <a class="reference internal" href="../install/env-setup.html#setup"><span class="std std-ref">GraphStorm Docker environment setup</span></a> to prepare your environment.</p>
</div>
<p>Now we can download and process the OGBN-MAG data with the command below.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python3<span class="w"> </span>/graphstorm/tools/gen_mag_dataset.py<span class="w"> </span>--savepath<span class="w"> </span>/data/ogbn-mag-lp/<span class="w"> </span>--edge-pct<span class="w"> </span><span class="m">0</span>.2
</pre></div>
</div>
<p>Because we use three GraphStorm instances in the cluster for model training, this command splits the MAG data into three partitions by specifying the <code class="docutils literal notranslate"><span class="pre">--num-parts</span></code> argument to <code class="docutils literal notranslate"><span class="pre">3</span></code>.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python3<span class="w"> </span>/graphstorm/tools/partition_graph_lp.py<span class="w"> </span>--dataset<span class="w"> </span>ogbn-mag<span class="w"> </span><span class="se">\</span>
<span class="w">                                                </span>--filepath<span class="w"> </span>/data/ogbn-mag-lp/<span class="w"> </span><span class="se">\</span>
<span class="w">                                                </span>--num-parts<span class="w"> </span><span class="m">3</span><span class="w"> </span><span class="se">\</span>
<span class="w">                                                </span>--balance-train<span class="w"> </span><span class="se">\</span>
<span class="w">                                                </span>--balance-edges<span class="w"> </span><span class="se">\</span>
<span class="w">                                                </span>--num-trainers-per-machine<span class="w"> </span><span class="m">4</span><span class="w"> </span><span class="se">\</span>
<span class="w">                                                </span>--target-etypes<span class="w"> </span>author,writes,paper<span class="w"> </span><span class="se">\</span>
<span class="w">                                                </span>--output<span class="w"> </span>/data/ogbn_mag_lp_3p
</pre></div>
</div>
<p>After this command completes successfully, the partitioned OGBN-MAG graph is stored in the <code class="docutils literal notranslate"><span class="pre">/data/ogbn_mag_lp_3p</span></code> folder whose structure is like the diagram below. Because the <code class="docutils literal notranslate"><span class="pre">/data/</span></code> folder is a shared filesystem, all instances in the cluster can access these files.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>/data/ogbn_mag_lp_3p
ogbn-mag.json
node_mapping.pt
edge_mapping.pt
<span class="p">|</span>-<span class="w"> </span>part0
<span class="w">    </span>edge_feat.dgl
<span class="w">    </span>graph.dgl
<span class="w">    </span>node_feat.dgl
<span class="p">|</span>-<span class="w"> </span>part1
<span class="w">    </span>edge_feat.dgl
<span class="w">    </span>graph.dgl
<span class="w">    </span>node_feat.dgl
<span class="p">|</span>-<span class="w"> </span>part2
<span class="w">    </span>edge_feat.dgl
<span class="w">    </span>graph.dgl
<span class="w">    </span>node_feat.dgl
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The two mapping files, <code class="docutils literal notranslate"><span class="pre">node_mapping.pt</span></code> and <code class="docutils literal notranslate"><span class="pre">edge_mapping.pt</span></code>, are used to record the mapping between the ogriginal node and edge ids in the raw data files and the ids of nodes and edges in the constructed graph. They are important for mapping the training and inference outputs. Therefore, DO NOT move or delete them.</p>
</div>
</section>
<section id="launch-training-on-one-container">
<h2>Launch Training on One Container<a class="headerlink" href="#launch-training-on-one-container" title="Permalink to this heading">#</a></h2>
<p>When graph partition data is ready, it is easy to launch a distributed training job. Pick a GraphStorm container, e.g. the container with IP address <code class="docutils literal notranslate"><span class="pre">172.37.11.221</span></code>, and run the following command.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python3<span class="w"> </span>-m<span class="w"> </span>graphstorm.run.gs_link_prediction<span class="w"> </span><span class="se">\</span>
<span class="w">           </span>--workspace<span class="w"> </span>/data/ogbn-mag-lp/<span class="w"> </span><span class="se">\</span>
<span class="w">           </span>--num-trainers<span class="w"> </span><span class="m">4</span><span class="w"> </span><span class="se">\</span>
<span class="w">           </span>--num-servers<span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">           </span>--num-samplers<span class="w"> </span><span class="m">0</span><span class="w"> </span><span class="se">\</span>
<span class="w">           </span>--part-config<span class="w"> </span>/data/ogbn_mag_lp_3p/ogbn-mag.json<span class="w"> </span><span class="se">\</span>
<span class="w">           </span>--ip-config<span class="w"> </span>/data/ip_list.txt<span class="w"> </span><span class="se">\</span>
<span class="w">           </span>--ssh-port<span class="w"> </span><span class="m">2222</span><span class="w"> </span><span class="se">\</span>
<span class="w">           </span>--cf<span class="w"> </span>/graphstorm/training_scripts/gsgnn_lp/mag_lp.yaml<span class="w"> </span><span class="se">\</span>
<span class="w">           </span>--node-feat-name<span class="w"> </span>paper:feat<span class="w"> </span><span class="se">\</span>
<span class="w">           </span>--save-model-path<span class="w"> </span>/data/ogbn-mag-lp/models/
</pre></div>
</div>
<p>That’s it! The command will initialize the training in all three GraphStorm containers, each of which will take a partition of the MAG graph and conduct link prediction traing collaborately.</p>
</section>
<section id="train-a-large-graph-ogbn-papers100m">
<h2>Train a Large Graph (OGBN-Papers100M)<a class="headerlink" href="#train-a-large-graph-ogbn-papers100m" title="Permalink to this heading">#</a></h2>
<p>The previous sections demonstrates GraphStorm’s distributed capability for a quick start. This section will use GraphStorm to train a large Graph data, i.e., <a class="reference external" href="https://ogb.stanford.edu/docs/nodeprop/#ogbn-papers100M">OGBN-Papers100M</a>,  that can hardly train an RGCN model on it in a single machine. The steps of training this large graph is nearly the same as the above section, and only need a few additional operations.</p>
<section id="id4">
<h3>Create a GraphStorm Cluster<a class="headerlink" href="#id4" title="Permalink to this heading">#</a></h3>
<p>In addition to the three GraphStorm instance created in the OGBN-MAG tutorial, to download and partition the OGBN-Papers100M graph, we need a new instance that has large memory, e.g., &gt;800GB. In this tutorial we use an AWS r6a.32xlarge instance, which has 1TB memory. For the instance, please follow the <a class="reference internal" href="../install/env-setup.html#setup"><span class="std std-ref">Environment Setup</span></a> description to setup GraphStorm Docker container environment. Once building the GraphStorm Docker image in this instance, use the following command to start a GraphStorm Docker container.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>docker<span class="w"> </span>run<span class="w"> </span>-v<span class="w"> </span>/path_to_data/:/data<span class="w"> </span><span class="se">\</span>
<span class="w">           </span>-v<span class="w"> </span>/dev/shm:/dev/shm<span class="w"> </span><span class="se">\</span>
<span class="w">           </span>--network<span class="o">=</span>host<span class="w"> </span><span class="se">\</span>
<span class="w">           </span>-d<span class="w"> </span>--name<span class="w"> </span><span class="nb">test</span><span class="w"> </span>graphstorm:local
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<ul class="simple">
<li><p>Use the “<strong>docker</strong>”, instead of “nvidia-docker” command to create the GraphStorm container because the new r6a.32xlarge instance does not have GPUs installed.</p></li>
<li><p>Make sure there is at least 300GB free space in the /path_to_data/ folder. It is better to use the shared file system folder so that the partitioned graph data can be easily shared to the GraphStorm cluster.</p></li>
</ul>
</div>
</section>
<section id="process-and-partition-a-graph">
<h3>Process and Partition a Graph<a class="headerlink" href="#process-and-partition-a-graph" title="Permalink to this heading">#</a></h3>
<p>Run the below command to download and partition the OGBN-Papers100M data for a node classification task, which will predict the category of a paper. Because the ogbn-papers100M is one of GraphStorm’s built-in datasets, we do not specify some arguments, such as <code class="docutils literal notranslate"><span class="pre">target-ntype</span></code>, <code class="docutils literal notranslate"><span class="pre">nlabel-field</span></code>, and <code class="docutils literal notranslate"><span class="pre">ntask-type</span></code>, which have been automatically handled by GraphStorm’s <a class="reference external" href="https://github.com/awslabs/graphstorm/blob/main/python/graphstorm/data/ogbn_datasets.py">ogbn_datasets.py</a>.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python3<span class="w"> </span>/graphstorm/tools/partition_graph.py<span class="w"> </span>--dataset<span class="w"> </span>ogbn-papers100M<span class="w"> </span><span class="se">\</span>
<span class="w">                                            </span>--filepath<span class="w"> </span>/data<span class="w"> </span><span class="se">\</span>
<span class="w">                                            </span>--num-parts<span class="w"> </span><span class="m">3</span><span class="w"> </span><span class="se">\</span>
<span class="w">                                            </span>--train-pct<span class="w"> </span><span class="m">0</span>.1<span class="w"> </span><span class="se">\</span>
<span class="w">                                            </span>--balance-train<span class="w"> </span><span class="se">\</span>
<span class="w">                                            </span>--balance-edges<span class="w"> </span><span class="se">\</span>
<span class="w">                                            </span>--output<span class="w"> </span>/data/ogbn_papers100M_3p<span class="w"> </span><span class="se">\</span>
</pre></div>
</div>
<p>Given the size of OGBN-Papers100M, the download and partition process could run more than 5 hours and consume around 700GB memory in peak. After the command completes, the partitioned OGBN-Papers100M graphs are stored in the <code class="docutils literal notranslate"><span class="pre">/data/ogbn_papers100M_3p</span></code> folder whose structure is the same as the OGBN-MAG’s.</p>
</section>
<section id="distribute-partitioned-graphs-and-configurations-to-all-instances">
<h3>Distribute Partitioned Graphs and Configurations to all Instances<a class="headerlink" href="#distribute-partitioned-graphs-and-configurations-to-all-instances" title="Permalink to this heading">#</a></h3>
<p>In this step, users need to copy these partitioned files to the shared file system of the GraphStorm cluster. And the IP list file creation and 2222 port open operations are identical to the above OGBN-MAG section.</p>
<p>For the OGBN-Papers100M data, we use a YAML file, <code class="docutils literal notranslate"><span class="pre">ogbn_papers100M_nc_p3.yaml</span></code>, that has the contents below.</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nn">---</span>
<span class="nt">version</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1.0</span>
<span class="nt">gsf</span><span class="p">:</span>
<span class="nt">basic</span><span class="p">:</span>
<span class="w">    </span><span class="nt">model_encoder_type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">rgcn</span>
<span class="w">    </span><span class="nt">backend</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">gloo</span>
<span class="w">    </span><span class="nt">verbose</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span>
<span class="w">    </span><span class="nt">no_validation</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span>
<span class="w">    </span><span class="nt">evaluation_frequency</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">500</span>
<span class="nt">gnn</span><span class="p">:</span>
<span class="w">    </span><span class="nt">num_layers</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">3</span>
<span class="w">    </span><span class="nt">hidden_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">128</span>
<span class="w">    </span><span class="nt">mini_batch_infer</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="nt">input</span><span class="p">:</span>
<span class="w">    </span><span class="nt">restore_model_path</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">output</span><span class="p">:</span>
<span class="w">    </span><span class="nt">save_model_path</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="w">    </span><span class="nt">save_embed_path</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">null</span>
<span class="nt">hyperparam</span><span class="p">:</span>
<span class="w">    </span><span class="nt">dropout</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.</span>
<span class="w">    </span><span class="nt">lr</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.001</span>
<span class="w">    </span><span class="nt">num_epochs</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">4</span>
<span class="w">    </span><span class="nt">fanout</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;5,10,15&quot;</span>
<span class="w">    </span><span class="nt">eval_fanout</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;5,10,15&quot;</span>
<span class="w">    </span><span class="nt">batch_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">128</span>
<span class="w">    </span><span class="nt">eval_batch_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">128</span>
<span class="w">    </span><span class="nt">wd_l2norm</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0</span>
<span class="nt">rgcn</span><span class="p">:</span>
<span class="w">    </span><span class="nt">num_bases</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">-1</span>
<span class="w">    </span><span class="nt">use_self_loop</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">true</span>
<span class="w">    </span><span class="nt">lp_decoder_type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">dot_product</span>
<span class="w">    </span><span class="nt">sparse_optimizer-lr</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1e-2</span>
<span class="w">    </span><span class="nt">use_node_embeddings</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">false</span>
<span class="nt">node_classification</span><span class="p">:</span>
<span class="w">    </span><span class="nt">target_ntype</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;node&quot;</span>
<span class="w">    </span><span class="nt">label_field</span><span class="p">:</span><span class="w"> </span><span class="s">&quot;labels&quot;</span>
<span class="w">    </span><span class="nt">num_classes</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">172</span>
</pre></div>
</div>
</section>
<section id="launch-training-in-one-container">
<h3>Launch Training in One Container<a class="headerlink" href="#launch-training-in-one-container" title="Permalink to this heading">#</a></h3>
<p>Launch the training for the OGBN-Papers100M is similar as the OGBN-MAG data. Pick a GraphStorm container, e.g. the container with IP address <code class="docutils literal notranslate"><span class="pre">172.37.11.221</span></code>, and run the following command.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python3<span class="w"> </span>-m<span class="w"> </span>graphstorm.run.gs_node_classification<span class="w"> </span><span class="se">\</span>
<span class="w">           </span>--workspace<span class="w"> </span>/data/<span class="w"> </span><span class="se">\</span>
<span class="w">           </span>--num-trainers<span class="w"> </span><span class="m">4</span><span class="w"> </span><span class="se">\</span>
<span class="w">           </span>--num-servers<span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="se">\</span>
<span class="w">           </span>--num-samplers<span class="w"> </span><span class="m">0</span><span class="w"> </span><span class="se">\</span>
<span class="w">           </span>--part-config<span class="w"> </span>/data/ogbn_papers100M_3p/ogbn-papers100M.json<span class="w"> </span><span class="se">\</span>
<span class="w">           </span>--ip-config<span class="w"> </span>/data/ip_list.txt<span class="w"> </span><span class="se">\</span>
<span class="w">           </span>--ssh-port<span class="w"> </span><span class="m">2222</span><span class="w"> </span><span class="se">\</span>
<span class="w">           </span>--graph-format<span class="w"> </span>csc,coo<span class="w"> </span><span class="se">\</span>
<span class="w">           </span>--cf<span class="w"> </span>/data/ogbn_papers100M_nc_p3.yaml<span class="w"> </span><span class="se">\</span>
<span class="w">           </span>--node-feat-name<span class="w"> </span>feat
</pre></div>
</div>
<p>Due to the size of Papers100M graph, it will take around six minutes for all GraphStorm containers in the cluster to load corresponding partitions before the training starts.</p>
<p>Given a cluster with three AWS g4dn.12xlarge instances, each of which has 48 Intel Xeon vCPUs, four Nvidia T4 GPUs, and 192GB memory, it takes around 45 minutes to train one epoch with the given configurations.</p>
</section>
</section>
</section>

        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          <a class="next-page" href="sagemaker.html">
              <div class="page-info">
                <div class="context">
                  <span>Next</span>
                </div>
                <div class="title">Use GraphStorm on SageMaker</div>
              </div>
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
            </a>
          <a class="prev-page" href="../configuration/configuration-run.html">
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
              <div class="page-info">
                <div class="context">
                  <span>Previous</span>
                </div>
                
                <div class="title">Training and Inference</div>
                
              </div>
            </a>
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; 2023, AGML team
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer">
      
      
      <div class="toc-sticky toc-scroll">
        <div class="toc-title-container">
          <span class="toc-title">
            On this page
          </span>
        </div>
        <div class="toc-tree-container">
          <div class="toc-tree">
            <ul>
<li><a class="reference internal" href="#">Use GraphStorm in a Distributed Cluster</a><ul>
<li><a class="reference internal" href="#create-a-graphstorm-cluster">Create a GraphStorm Cluster</a><ul>
<li><a class="reference internal" href="#setup-the-instance-of-a-cluster">Setup the instance of a cluster</a></li>
<li><a class="reference internal" href="#setup-of-a-shared-file-system-for-the-cluster">Setup of a shared file system for the cluster</a></li>
<li><a class="reference internal" href="#create-graphstorm-container-by-mounting-the-nfs-folder">Create GraphStorm container by mounting the NFS folder</a></li>
</ul>
</li>
<li><a class="reference internal" href="#setup-the-ip-address-file-and-check-port-status">Setup the IP address file and check port status</a><ul>
<li><a class="reference internal" href="#collect-the-ip-list">Collect the IP list</a></li>
<li><a class="reference internal" href="#check-port">Check port</a></li>
</ul>
</li>
<li><a class="reference internal" href="#partition-a-graph">Partition a Graph</a></li>
<li><a class="reference internal" href="#launch-training-on-one-container">Launch Training on One Container</a></li>
<li><a class="reference internal" href="#train-a-large-graph-ogbn-papers100m">Train a Large Graph (OGBN-Papers100M)</a><ul>
<li><a class="reference internal" href="#id4">Create a GraphStorm Cluster</a></li>
<li><a class="reference internal" href="#process-and-partition-a-graph">Process and Partition a Graph</a></li>
<li><a class="reference internal" href="#distribute-partitioned-graphs-and-configurations-to-all-instances">Distribute Partitioned Graphs and Configurations to all Instances</a></li>
<li><a class="reference internal" href="#launch-training-in-one-container">Launch Training in One Container</a></li>
</ul>
</li>
</ul>
</li>
</ul>

          </div>
        </div>
      </div>
      
      
    </aside>
  </div>
</div><script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/sphinx_highlight.js"></script>
    <script src="../_static/scripts/furo.js"></script>
    </body>
</html>